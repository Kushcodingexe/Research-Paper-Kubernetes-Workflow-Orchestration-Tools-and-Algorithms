apiVersion: batch/v1
kind: Job
metadata:
  creationTimestamp: "2026-01-01T11:03:28Z"
  generation: 1
  labels:
    app: resilience-simulation
    platform: native-kubernetes
  name: resilience-bench-13-163328
  namespace: default
  resourceVersion: "1285260"
  uid: b5ad1704-0986-432a-bdbb-595e0996b296
spec:
  backoffLimit: 0
  completionMode: NonIndexed
  completions: 1
  manualSelector: false
  parallelism: 1
  podReplacementPolicy: TerminatingOrFailed
  selector:
    matchLabels:
      batch.kubernetes.io/controller-uid: b5ad1704-0986-432a-bdbb-595e0996b296
  suspend: false
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: resilience-simulation
        batch.kubernetes.io/controller-uid: b5ad1704-0986-432a-bdbb-595e0996b296
        batch.kubernetes.io/job-name: resilience-bench-13-163328
        controller-uid: b5ad1704-0986-432a-bdbb-595e0996b296
        job-name: resilience-bench-13-163328
        platform: native-kubernetes
    spec:
      containers:
      - args:
        - |
          set -e

          # ===== CONFIGURATION =====
          export RUN_ID="native-$(date +%Y%m%d-%H%M%S)-${POD_NAME##*-}"
          export LOG_DIR="/app/logs/${RUN_ID}"
          export LOG_FILE="${LOG_DIR}/full_execution.log"
          export METRICS_FILE="${LOG_DIR}/metrics.txt"
          export TIMING_FILE="${LOG_DIR}/timing.csv"

          mkdir -p "${LOG_DIR}"

          # ===== LOGGING HELPERS =====
          log() {
              local msg="[$(date '+%Y-%m-%d %H:%M:%S')] $1"
              echo "$msg" | tee -a "${LOG_FILE}"
          }

          log_section() {
              echo "" | tee -a "${LOG_FILE}"
              echo "================================================================" | tee -a "${LOG_FILE}"
              echo " $1" | tee -a "${LOG_FILE}"
              echo " Time: $(date '+%Y-%m-%d %H:%M:%S')" | tee -a "${LOG_FILE}"
              echo "================================================================" | tee -a "${LOG_FILE}"
          }

          record_timing() {
              local step="$1"
              local start="$2"
              local end="$3"
              local duration=$((end - start))
              echo "${step},${start},${end},${duration}" >> "${TIMING_FILE}"
              log "TIMING: ${step} completed in ${duration} seconds"
          }

          # ===== INITIALIZE METRICS =====
          WORKFLOW_START=$(date +%s)

          # CSV Header for timing
          echo "step,start_epoch,end_epoch,duration_seconds" > "${TIMING_FILE}"

          # Metrics file header
          cat > "${METRICS_FILE}" << EOF
          # Resilience Simulation Metrics - Native Kubernetes Job
          # Generated: $(date '+%Y-%m-%d %H:%M:%S')

          PLATFORM=Native_Kubernetes
          RUN_ID=${RUN_ID}
          NODE_NAME=${NODE_NAME}
          POD_NAME=${POD_NAME}
          WORKFLOW_START_EPOCH=${WORKFLOW_START}
          WORKFLOW_START_ISO=$(date -d @${WORKFLOW_START} '+%Y-%m-%dT%H:%M:%S%z' 2>/dev/null || date '+%Y-%m-%dT%H:%M:%S%z')
          EOF

          log_section "INITIALIZATION"
          log "Run ID: ${RUN_ID}"
          log "Platform: Native Kubernetes Job"
          log "Node: ${NODE_NAME}"
          log "Pod: ${POD_NAME}"
          log "Log Directory: ${LOG_DIR}"

          # ===== STEP 1: PARALLEL HEALTH CHECKS =====
          log_section "STEP 1: PARALLEL HEALTH CHECKS (3x)"

          HEALTH_CHECK_START=$(date +%s)
          echo "HEALTH_CHECK_START_EPOCH=${HEALTH_CHECK_START}" >> "${METRICS_FILE}"

          # Create temp files for parallel execution output
          HC_LOG1="/tmp/health_check_1.log"
          HC_LOG2="/tmp/health_check_2.log"
          HC_LOG3="/tmp/health_check_3.log"

          log "Starting 3 parallel health checks..."

          # Run 3 health checks in parallel
          python3 /app/rack_resiliency_to_host.py health-check --stabilization-time 10 > "${HC_LOG1}" 2>&1 &
          PID1=$!

          python3 /app/rack_resiliency_to_host.py health-check --stabilization-time 10 > "${HC_LOG2}" 2>&1 &
          PID2=$!

          python3 /app/rack_resiliency_to_host.py health-check --stabilization-time 10 > "${HC_LOG3}" 2>&1 &
          PID3=$!

          # Wait for all to complete
          wait $PID1 && HC1_STATUS="SUCCESS" || HC1_STATUS="FAILED"
          wait $PID2 && HC2_STATUS="SUCCESS" || HC2_STATUS="FAILED"
          wait $PID3 && HC3_STATUS="SUCCESS" || HC3_STATUS="FAILED"

          HEALTH_CHECK_END=$(date +%s)

          # Append health check logs to main log
          log "--- Health Check 1 Output (${HC1_STATUS}) ---"
          cat "${HC_LOG1}" >> "${LOG_FILE}"
          log "--- Health Check 2 Output (${HC2_STATUS}) ---"
          cat "${HC_LOG2}" >> "${LOG_FILE}"
          log "--- Health Check 3 Output (${HC3_STATUS}) ---"
          cat "${HC_LOG3}" >> "${LOG_FILE}"

          record_timing "HEALTH_CHECKS_PARALLEL" "${HEALTH_CHECK_START}" "${HEALTH_CHECK_END}"

          echo "HEALTH_CHECK_END_EPOCH=${HEALTH_CHECK_END}" >> "${METRICS_FILE}"
          echo "HEALTH_CHECK_DURATION_SECONDS=$((HEALTH_CHECK_END - HEALTH_CHECK_START))" >> "${METRICS_FILE}"
          echo "HEALTH_CHECK_1_STATUS=${HC1_STATUS}" >> "${METRICS_FILE}"
          echo "HEALTH_CHECK_2_STATUS=${HC2_STATUS}" >> "${METRICS_FILE}"
          echo "HEALTH_CHECK_3_STATUS=${HC3_STATUS}" >> "${METRICS_FILE}"

          # ===== STEP 2: NODE FAILURE SIMULATION =====
          log_section "STEP 2: NODE FAILURE SIMULATION"

          NODE_SIM_START=$(date +%s)
          echo "NODE_SIM_START_EPOCH=${NODE_SIM_START}" >> "${METRICS_FILE}"

          log "Starting node failure simulation (stabilization: 60s)..."

          python3 /app/rack_resiliency_to_host.py simulate-node --stabilization-time 60 2>&1 | tee -a "${LOG_FILE}"
          NODE_SIM_STATUS=$?

          NODE_SIM_END=$(date +%s)
          record_timing "NODE_SIMULATION" "${NODE_SIM_START}" "${NODE_SIM_END}"

          echo "NODE_SIM_END_EPOCH=${NODE_SIM_END}" >> "${METRICS_FILE}"
          echo "NODE_SIM_DURATION_SECONDS=$((NODE_SIM_END - NODE_SIM_START))" >> "${METRICS_FILE}"
          echo "NODE_SIM_STATUS=$([ $NODE_SIM_STATUS -eq 0 ] && echo 'SUCCESS' || echo 'FAILED')" >> "${METRICS_FILE}"

          # ===== STEP 3: INTERIM HEALTH CHECK =====
          log_section "STEP 3: INTERIM HEALTH CHECK"

          INTERIM_HC_START=$(date +%s)
          echo "INTERIM_HC_START_EPOCH=${INTERIM_HC_START}" >> "${METRICS_FILE}"

          python3 /app/rack_resiliency_to_host.py health-check --stabilization-time 10 2>&1 | tee -a "${LOG_FILE}"

          INTERIM_HC_END=$(date +%s)
          record_timing "INTERIM_HEALTH_CHECK" "${INTERIM_HC_START}" "${INTERIM_HC_END}"

          echo "INTERIM_HC_END_EPOCH=${INTERIM_HC_END}" >> "${METRICS_FILE}"
          echo "INTERIM_HC_DURATION_SECONDS=$((INTERIM_HC_END - INTERIM_HC_START))" >> "${METRICS_FILE}"

          # ===== STEP 4: RACK FAILURE SIMULATION =====
          log_section "STEP 4: RACK FAILURE SIMULATION"

          RACK_SIM_START=$(date +%s)
          echo "RACK_SIM_START_EPOCH=${RACK_SIM_START}" >> "${METRICS_FILE}"

          log "Starting rack failure simulation (stabilization: 120s, downtime: 60s)..."

          python3 /app/rack_resiliency_to_host.py simulate-rack --stabilization-time 120 --downtime 60 2>&1 | tee -a "${LOG_FILE}"
          RACK_SIM_STATUS=$?

          RACK_SIM_END=$(date +%s)
          record_timing "RACK_SIMULATION" "${RACK_SIM_START}" "${RACK_SIM_END}"

          echo "RACK_SIM_END_EPOCH=${RACK_SIM_END}" >> "${METRICS_FILE}"
          echo "RACK_SIM_DURATION_SECONDS=$((RACK_SIM_END - RACK_SIM_START))" >> "${METRICS_FILE}"
          echo "RACK_SIM_STATUS=$([ $RACK_SIM_STATUS -eq 0 ] && echo 'SUCCESS' || echo 'FAILED')" >> "${METRICS_FILE}"

          # ===== STEP 5: FINAL HEALTH CHECK =====
          log_section "STEP 5: FINAL HEALTH CHECK"

          FINAL_HC_START=$(date +%s)
          echo "FINAL_HC_START_EPOCH=${FINAL_HC_START}" >> "${METRICS_FILE}"

          python3 /app/rack_resiliency_to_host.py health-check --stabilization-time 10 2>&1 | tee -a "${LOG_FILE}"

          FINAL_HC_END=$(date +%s)
          record_timing "FINAL_HEALTH_CHECK" "${FINAL_HC_START}" "${FINAL_HC_END}"

          echo "FINAL_HC_END_EPOCH=${FINAL_HC_END}" >> "${METRICS_FILE}"
          echo "FINAL_HC_DURATION_SECONDS=$((FINAL_HC_END - FINAL_HC_START))" >> "${METRICS_FILE}"

          # ===== WORKFLOW COMPLETE =====
          WORKFLOW_END=$(date +%s)
          TOTAL_DURATION=$((WORKFLOW_END - WORKFLOW_START))

          log_section "WORKFLOW COMPLETE"
          log "Total Duration: ${TOTAL_DURATION} seconds"
          log "Log files saved to: ${LOG_DIR}"

          # Final metrics
          cat >> "${METRICS_FILE}" << EOF

          # Final Summary
          WORKFLOW_END_EPOCH=${WORKFLOW_END}
          WORKFLOW_END_ISO=$(date -d @${WORKFLOW_END} '+%Y-%m-%dT%H:%M:%S%z' 2>/dev/null || date '+%Y-%m-%dT%H:%M:%S%z')
          TOTAL_DURATION_SECONDS=${TOTAL_DURATION}
          TOTAL_DURATION_FORMATTED=$(printf '%02d:%02d:%02d' $((TOTAL_DURATION/3600)) $((TOTAL_DURATION%3600/60)) $((TOTAL_DURATION%60)))
          EOF

          # Print summary
          log ""
          log "===== TIMING SUMMARY ====="
          cat "${TIMING_FILE}" | tee -a "${LOG_FILE}"
          log ""
          log "===== METRICS SUMMARY ====="
          cat "${METRICS_FILE}" | tee -a "${LOG_FILE}"

          # Fix permissions for vagrant user
          chmod -R 755 "${LOG_DIR}"
          chown -R 1000:1000 "${LOG_DIR}" 2>/dev/null || true

          log "Native Kubernetes Job completed successfully!"
        command:
        - /bin/bash
        - -c
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.nodeName
        - name: POD_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        image: kushsahni1/chaos-sim:latest
        imagePullPolicy: Always
        name: resilience-controller
        resources:
          limits:
            cpu: 500m
            memory: 512Mi
          requests:
            cpu: 100m
            memory: 256Mi
        securityContext:
          runAsGroup: 0
          runAsUser: 0
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /app/logs
          name: log-vol
      dnsPolicy: ClusterFirst
      nodeSelector:
        kubernetes.io/hostname: master-m003
      restartPolicy: Never
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: chaos-admin
      serviceAccountName: chaos-admin
      terminationGracePeriodSeconds: 30
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/control-plane
        operator: Exists
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
        operator: Exists
      volumes:
      - hostPath:
          path: /home/vagrant/k8s-sim-logs/native-runs
          type: DirectoryOrCreate
        name: log-vol
  ttlSecondsAfterFinished: 86400
status:
  completionTime: "2026-01-01T11:12:15Z"
  conditions:
  - lastProbeTime: "2026-01-01T11:12:15Z"
    lastTransitionTime: "2026-01-01T11:12:15Z"
    message: Reached expected number of succeeded pods
    reason: CompletionsReached
    status: "True"
    type: SuccessCriteriaMet
  - lastProbeTime: "2026-01-01T11:12:15Z"
    lastTransitionTime: "2026-01-01T11:12:15Z"
    message: Reached expected number of succeeded pods
    reason: CompletionsReached
    status: "True"
    type: Complete
  ready: 0
  startTime: "2026-01-01T11:03:28Z"
  succeeded: 1
  terminating: 0
  uncountedTerminatedPods: {}

[37mresilience-heft-jx8fh-heft-initialize-4056367215: ================================================[0m
[37mresilience-heft-jx8fh-heft-initialize-4056367215: HEFT SCHEDULER INITIALIZATION[0m
[37mresilience-heft-jx8fh-heft-initialize-4056367215: ================================================[0m
[37mresilience-heft-jx8fh-heft-initialize-4056367215: HEFT Decision:[0m
[37mresilience-heft-jx8fh-heft-initialize-4056367215:   Execution Node: master-m003[0m
[37mresilience-heft-jx8fh-heft-initialize-4056367215:   Execution Zone: R3[0m
[37mresilience-heft-jx8fh-heft-initialize-4056367215:   Exclude Node from simulation: worker-w005[0m
[37mresilience-heft-jx8fh-heft-initialize-4056367215:   Exclude Zone from rack sim: R3[0m
[37mresilience-heft-jx8fh-heft-initialize-4056367215: HEFT initialization complete[0m
[37mresilience-heft-jx8fh-heft-initialize-4056367215: time="2026-01-06T05:51:21.235Z" level=info msg="sub-process exited" argo=true error="<nil>"[0m
[37mresilience-heft-jx8fh-heft-initialize-4056367215: time="2026-01-06T05:51:21.235Z" level=info msg="/tmp/heft-exclude-node -> /var/run/argo/outputs/parameters//tmp/heft-exclude-node" argo=true[0m
[37mresilience-heft-jx8fh-heft-initialize-4056367215: time="2026-01-06T05:51:21.236Z" level=info msg="/tmp/heft-exclude-zone -> /var/run/argo/outputs/parameters//tmp/heft-exclude-zone" argo=true[0m
[36mresilience-heft-jx8fh-health-check-3032273300: Log directory created/verified: /app/logs[0m
[36mresilience-heft-jx8fh-health-check-3032273300: File logging configured successfully[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,210 [INFO] Loaded in-cluster Kubernetes config[0m
[35mresilience-heft-jx8fh-health-check-3049050919: Log directory created/verified: /app/logs[0m
[35mresilience-heft-jx8fh-health-check-3049050919: File logging configured successfully[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,211 [INFO] Loaded in-cluster Kubernetes config[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,219 [INFO] Running on host: resilience-heft-jx8fh-health-check-3032273300[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,219 [INFO] Running on host: resilience-heft-jx8fh-health-check-3049050919[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,219 [INFO] Detected current node: master-m003, zone: R3[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,219 [INFO] Detected current node: master-m003, zone: R3[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,219 [INFO] Checking if we have permissions to modify nodes...[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,220 [INFO] Checking if we have permissions to modify nodes...[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,283 [INFO] Testing permissions using node: master-m001[0m
[37mresilience-heft-jx8fh-health-check-3065828538: Log directory created/verified: /app/logs[0m
[37mresilience-heft-jx8fh-health-check-3065828538: File logging configured successfully[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,288 [INFO] Loaded in-cluster Kubernetes config[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,289 [INFO] Running on host: resilience-heft-jx8fh-health-check-3065828538[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,289 [INFO] Detected current node: master-m003, zone: R3[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,289 [INFO] Checking if we have permissions to modify nodes...[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,292 [INFO] Testing permissions using node: master-m001[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,295 [INFO] Permission check successful - we can modify nodes[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,295 [INFO] Using real Kubernetes API for node control[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,296 [INFO] Action received: health-check[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,296 [INFO] Stabilization time: 10 seconds[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,296 [INFO] Starting full health check[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,296 [INFO] [0m
[36mresilience-heft-jx8fh-health-check-3032273300: ============ DETAILED NODE STATUS ============[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,296 [INFO] Basic Node Information (kubectl get nodes -o wide):[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,303 [INFO] Permission check successful - we can modify nodes[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,303 [INFO] Using real Kubernetes API for node control[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,304 [INFO] Action received: health-check[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,304 [INFO] Stabilization time: 10 seconds[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,304 [INFO] Starting full health check[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,304 [INFO] [0m
[35mresilience-heft-jx8fh-health-check-3049050919: ============ DETAILED NODE STATUS ============[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,304 [INFO] Basic Node Information (kubectl get nodes -o wide):[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,323 [INFO] Testing permissions using node: master-m001[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,333 [INFO] Permission check successful - we can modify nodes[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,333 [INFO] Using real Kubernetes API for node control[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,334 [INFO] Action received: health-check[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,334 [INFO] Stabilization time: 10 seconds[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,334 [INFO] Starting full health check[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,334 [INFO] [0m
[37mresilience-heft-jx8fh-health-check-3065828538: ============ DETAILED NODE STATUS ============[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,334 [INFO] Basic Node Information (kubectl get nodes -o wide):[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,793 [INFO]   NAME          STATUS   ROLES           AGE   VERSION    INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,794 [INFO]   master-m001   Ready    control-plane   11d   v1.32.11   192.168.56.101   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,794 [INFO]   master-m002   Ready    control-plane   11d   v1.32.11   192.168.56.102   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,794 [INFO]   master-m003   Ready    control-plane   11d   v1.32.11   192.168.56.103   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,794 [INFO]   worker-w001   Ready    <none>          11d   v1.32.11   192.168.56.104   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,794 [INFO]   worker-w002   Ready    <none>          11d   v1.32.11   192.168.56.105   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,794 [INFO]   worker-w003   Ready    <none>          11d   v1.32.11   192.168.56.106   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,794 [INFO]   worker-w004   Ready    <none>          11d   v1.32.11   192.168.56.107   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,794 [INFO]   worker-w005   Ready    <none>          11d   v1.32.11   192.168.56.108   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,795 [INFO]   worker-w006   Ready    <none>          11d   v1.32.11   192.168.56.109   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,795 [INFO] [0m
[36mresilience-heft-jx8fh-health-check-3032273300: Enhanced Node Status (with taint and cordon indicators):[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:43,795 [INFO]   NAME                STATUS    ROLES           ZONE   CORDONED   TAINTS[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,796 [INFO]   NAME          STATUS   ROLES           AGE   VERSION    INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,797 [INFO]   master-m001   Ready    control-plane   11d   v1.32.11   192.168.56.101   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,797 [INFO]   master-m002   Ready    control-plane   11d   v1.32.11   192.168.56.102   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,797 [INFO]   master-m003   Ready    control-plane   11d   v1.32.11   192.168.56.103   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,797 [INFO]   worker-w001   Ready    <none>          11d   v1.32.11   192.168.56.104   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,797 [INFO]   worker-w002   Ready    <none>          11d   v1.32.11   192.168.56.105   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,797 [INFO]   worker-w003   Ready    <none>          11d   v1.32.11   192.168.56.106   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,797 [INFO]   worker-w004   Ready    <none>          11d   v1.32.11   192.168.56.107   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,797 [INFO]   worker-w005   Ready    <none>          11d   v1.32.11   192.168.56.108   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,797 [INFO]   worker-w006   Ready    <none>          11d   v1.32.11   192.168.56.109   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,797 [INFO] [0m
[37mresilience-heft-jx8fh-health-check-3065828538: Enhanced Node Status (with taint and cordon indicators):[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:43,797 [INFO]   NAME                STATUS    ROLES           ZONE   CORDONED   TAINTS[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,804 [INFO]   NAME          STATUS   ROLES           AGE   VERSION    INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,804 [INFO]   master-m001   Ready    control-plane   11d   v1.32.11   192.168.56.101   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,804 [INFO]   master-m002   Ready    control-plane   11d   v1.32.11   192.168.56.102   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,807 [INFO]   master-m003   Ready    control-plane   11d   v1.32.11   192.168.56.103   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,807 [INFO]   worker-w001   Ready    <none>          11d   v1.32.11   192.168.56.104   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,807 [INFO]   worker-w002   Ready    <none>          11d   v1.32.11   192.168.56.105   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,807 [INFO]   worker-w003   Ready    <none>          11d   v1.32.11   192.168.56.106   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,807 [INFO]   worker-w004   Ready    <none>          11d   v1.32.11   192.168.56.107   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,807 [INFO]   worker-w005   Ready    <none>          11d   v1.32.11   192.168.56.108   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,807 [INFO]   worker-w006   Ready    <none>          11d   v1.32.11   192.168.56.109   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,807 [INFO] [0m
[35mresilience-heft-jx8fh-health-check-3049050919: Enhanced Node Status (with taint and cordon indicators):[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:43,807 [INFO]   NAME                STATUS    ROLES           ZONE   CORDONED   TAINTS[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:44,114 [INFO]   master-m001     Ready  ‚úì worker         R1    No       node-role.kubernetes.io/control-plane [0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:44,126 [INFO]   master-m001     Ready  ‚úì worker         R1    No       node-role.kubernetes.io/control-plane [0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:44,154 [INFO]   master-m001     Ready  ‚úì worker         R1    No       node-role.kubernetes.io/control-plane [0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:44,397 [INFO]   master-m002     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:44,423 [INFO]   master-m002     Ready  ‚úì worker         R2    No       None [0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:44,457 [INFO]   master-m002     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:44,640 [INFO]   master-m003     Ready  ‚úì worker         R3    No       None [0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:44,715 [INFO]   master-m003     Ready  ‚úì worker         R3    No       None [0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:44,771 [INFO]   master-m003     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:44,894 [INFO]   worker-w001     Ready  ‚úì worker         R1    No       None [0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:44,945 [INFO]   worker-w001     Ready  ‚úì worker         R1    No       None [0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:45,130 [INFO]   worker-w001     Ready  ‚úì worker         R1    No       None [0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:45,169 [INFO]   worker-w002     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:45,207 [INFO]   worker-w002     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:45,380 [INFO]   worker-w003     Ready  ‚úì worker         R2    No       None [0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:45,462 [INFO]   worker-w002     Ready  ‚úì worker         R1    No       None [0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:45,472 [INFO]   worker-w003     Ready  ‚úì worker         R2    No       None [0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:45,693 [INFO]   worker-w004     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:45,781 [INFO]   worker-w004     Ready  ‚úì worker         R2    No       None [0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:45,814 [INFO]   worker-w003     Ready  ‚úì worker         R2    No       None [0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:45,933 [INFO]   worker-w005     Ready  ‚úì worker         R3    No       None [0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,025 [INFO]   worker-w004     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,090 [INFO]   worker-w005     Ready  ‚úì worker         R3    No       None [0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,188 [INFO]   worker-w006     Ready  ‚úì worker         R3    No       None [0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,190 [INFO] [0m
[37mresilience-heft-jx8fh-health-check-3065828538: Legend:[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,190 [INFO]   ‚úì = Node is Ready[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,190 [INFO]   ‚ö†Ô∏è = Warning indicator (NotReady, Cordoned, or has simulated-failure taint)[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,191 [INFO] ============ DETAILED POD INFORMATION ============[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,191 [INFO] Running 'kubectl get pods -o wide' to show detailed pod placement:[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,357 [INFO]   worker-w006     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,358 [INFO] [0m
[36mresilience-heft-jx8fh-health-check-3032273300: Legend:[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,358 [INFO]   ‚úì = Node is Ready[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,358 [INFO]   ‚ö†Ô∏è = Warning indicator (NotReady, Cordoned, or has simulated-failure taint)[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,359 [INFO] ============ DETAILED POD INFORMATION ============[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,359 [INFO] Running 'kubectl get pods -o wide' to show detailed pod placement:[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,376 [INFO]   worker-w005     Ready  ‚úì worker         R3    No       None [0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,537 [INFO]   NAMESPACE     NAME                                                    READY   STATUS      RESTARTS        AGE    IP                NODE          NOMINATED NODE   READINESS GATES[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,549 [INFO]   argo          argo-server-5c69cb69db-gdkl6                            1/1     Running     0               8d     192.168.221.65    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,549 [INFO]   argo          resilience-bench-ptngm-initialize-metrics-940927476     0/2     Completed   0               3d7h   192.168.221.125   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,550 [INFO]   argo          resilience-bench-ptngm-run-health-check-1168793163      0/2     Completed   0               3d7h   192.168.221.67    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,550 [INFO]   argo          resilience-bench-ptngm-run-health-check-1185570782      0/2     Completed   0               3d7h   192.168.221.66    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,550 [INFO]   argo          resilience-bench-ptngm-run-health-check-1202348401      0/2     Completed   0               3d7h   192.168.221.122   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,550 [INFO]   argo          resilience-bench-wf87f-initialize-metrics-3677018408    0/2     Completed   0               3d9h   192.168.221.100   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,550 [INFO]   argo          resilience-bench-wf87f-run-health-check-2914150102      0/2     Completed   0               3d9h   192.168.221.105   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,550 [INFO]   argo          resilience-bench-wf87f-run-health-check-3931060015      0/2     Completed   0               3d9h   192.168.221.104   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,550 [INFO]   argo          resilience-bench-wf87f-run-health-check-3947837634      0/2     Completed   0               3d9h   192.168.221.98    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,550 [INFO]   argo          resilience-bench-wf87f-run-health-check-3964615253      0/2     Completed   0               3d9h   192.168.221.103   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,551 [INFO]   argo          resilience-bench-wf87f-run-node-simulation-4173146970   0/2     Completed   0               3d9h   192.168.221.101   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,551 [INFO]   argo          resilience-bench-wf87f-run-rack-simulation-1356070019   0/2     Completed   0               3d9h   192.168.221.109   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,551 [INFO]   argo          resilience-heft-4cqbx-health-check-1589398418           0/2     Error       0               16h    192.168.15.231    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,551 [INFO]   argo          resilience-heft-4cqbx-heft-initialize-2594215169        0/2     Completed   0               16h    192.168.221.79    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,551 [INFO]   argo          resilience-heft-76kbp-health-check-270747540            0/2     Error       0               16h    192.168.15.237    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,551 [INFO]   argo          resilience-heft-76kbp-heft-initialize-3574960751        0/2     Completed   0               16h    192.168.221.86    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,551 [INFO]   argo          resilience-heft-b85xr-health-check-2840770649           0/2     Error       0               16h    192.168.15.240    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,551 [INFO]   argo          resilience-heft-b85xr-heft-initialize-1754406316        0/2     Completed   0               16h    192.168.221.88    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,551 [INFO]   argo          resilience-heft-fdw9f-health-check-1896357264           0/2     Error       0               16h    192.168.15.235    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,551 [INFO]   argo          resilience-heft-fdw9f-heft-initialize-2651619139        0/2     Completed   0               16h    192.168.221.77    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,551 [INFO]   argo          resilience-heft-gf256-health-check-980174358            0/2     Error       0               16h    192.168.15.236    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,551 [INFO]   argo          resilience-heft-gf256-heft-initialize-1548293021        0/2     Completed   0               16h    192.168.221.84    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,552 [INFO]   argo          resilience-heft-gxwpg-health-check-3445304423           0/2     Error       0               16h    192.168.15.233    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,552 [INFO]   argo          resilience-heft-gxwpg-heft-initialize-2377397022        0/2     Completed   0               16h    192.168.221.81    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,552 [INFO]   argo          resilience-heft-jx8fh-health-check-3032273300           2/2     Running     0               19s    192.168.221.72    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,552 [INFO]   argo          resilience-heft-jx8fh-health-check-3049050919           2/2     Running     0               19s    192.168.221.76    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,552 [INFO]   argo          resilience-heft-jx8fh-health-check-3065828538           2/2     Running     0               19s    192.168.221.74    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,552 [INFO]   argo          resilience-heft-jx8fh-heft-initialize-4056367215        0/2     Completed   0               29s    192.168.221.73    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,552 [INFO]   argo          resilience-heft-pc2kb-health-check-3258812212           0/2     Error       0               16h    192.168.15.238    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,552 [INFO]   argo          resilience-heft-pc2kb-heft-initialize-321333135         0/2     Completed   0               16h    192.168.221.83    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,552 [INFO]   argo          resilience-heft-qsmch-health-check-283908068            0/2     Error       0               16h    192.168.15.232    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          resilience-heft-qsmch-heft-initialize-1908810015        0/2     Completed   0               16h    192.168.221.82    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          resilience-heft-r2w8l-health-check-366927355            0/2     Error       0               16h    192.168.15.239    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          resilience-heft-r2w8l-heft-initialize-3054048250        0/2     Completed   0               16h    192.168.221.85    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          resilience-heft-t988k-health-check-612195296            0/2     Error       0               16h    192.168.15.234    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          resilience-heft-t988k-heft-initialize-164752883         0/2     Completed   0               16h    192.168.221.80    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          resilience-heft-vlt2m-health-check-2709447919           0/2     Error       0               15h    192.168.221.119   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          resilience-heft-vlt2m-health-check-2726225538           0/2     Error       0               15h    192.168.221.120   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          resilience-heft-vlt2m-health-check-2743003157           0/2     Error       0               15h    192.168.221.121   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          resilience-heft-vlt2m-heft-initialize-840404112         0/2     Completed   0               15h    192.168.221.118   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          resilience-heft-x86wd-health-check-2184182048           0/2     Error       0               15h    192.168.221.123   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          resilience-heft-x86wd-health-check-2200959667           0/2     Error       0               15h    192.168.221.125   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          resilience-heft-x86wd-health-check-2234514905           0/2     Error       0               15h    192.168.221.124   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          resilience-heft-x86wd-heft-initialize-2152040770        0/2     Completed   0               15h    192.168.221.127   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   argo          workflow-controller-ccbd949dc-t4rx9                     1/1     Running     1 (116m ago)    15h    192.168.195.243   worker-w002   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   kube-system   calico-kube-controllers-7498b9bb4c-xd7tb                1/1     Running     0               2d5h   192.168.191.108   worker-w006   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   kube-system   calico-node-4zhd4                                       1/1     Running     0               11d    192.168.56.105    worker-w002   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   kube-system   calico-node-75nx6                                       1/1     Running     0               11d    192.168.56.109    worker-w006   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   kube-system   calico-node-7lkdq                                       1/1     Running     0               11d    192.168.56.104    worker-w001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   kube-system   calico-node-85f8c                                       1/1     Running     0               11d    192.168.56.102    master-m002   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   kube-system   calico-node-j8nb9                                       1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,553 [INFO]   kube-system   calico-node-lbcb2                                       1/1     Running     0               11d    192.168.56.106    worker-w003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   calico-node-wlr5v                                       1/1     Running     0               11d    192.168.56.107    worker-w004   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   calico-node-xnzjw                                       1/1     Running     0               11d    192.168.56.103    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   calico-node-xsltn                                       1/1     Running     0               11d    192.168.56.108    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   coredns-668d6bf9bc-2f74f                                1/1     Running     0               2d6h   192.168.15.230    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   coredns-668d6bf9bc-qnzjq                                1/1     Running     0               14h    192.168.132.176   worker-w001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   etcd-master-m001                                        1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   kube-apiserver-master-m001                              1/1     Running     1 (3d2h ago)    11d    192.168.56.101    master-m001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   kube-controller-manager-master-m001                     1/1     Running     13 (115m ago)   11d    192.168.56.101    master-m001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   kube-proxy-5lzhj                                        1/1     Running     0               11d    192.168.56.102    master-m002   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   kube-proxy-7jqkv                                        1/1     Running     0               11d    192.168.56.109    worker-w006   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   kube-proxy-cv5dt                                        1/1     Running     0               11d    192.168.56.108    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   kube-proxy-fvpmr                                        1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   kube-proxy-hgs5z                                        1/1     Running     0               11d    192.168.56.106    worker-w003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   kube-proxy-kmgqr                                        1/1     Running     0               11d    192.168.56.105    worker-w002   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   kube-proxy-rdbz5                                        1/1     Running     0               11d    192.168.56.107    worker-w004   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   kube-proxy-w8mnb                                        1/1     Running     0               11d    192.168.56.103    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   kube-proxy-x9jxr                                        1/1     Running     0               11d    192.168.56.104    worker-w001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO]   kube-system   kube-scheduler-master-m001                              1/1     Running     12 (115m ago)   11d    192.168.56.101    master-m001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,554 [INFO] [0m
[37mresilience-heft-jx8fh-health-check-3065828538: Pod distribution by node:[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,595 [INFO]   NAMESPACE     NAME                                                    READY   STATUS      RESTARTS        AGE    IP                NODE          NOMINATED NODE   READINESS GATES[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,596 [INFO]   argo          argo-server-5c69cb69db-gdkl6                            1/1     Running     0               8d     192.168.221.65    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,596 [INFO]   argo          resilience-bench-ptngm-initialize-metrics-940927476     0/2     Completed   0               3d7h   192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,596 [INFO]   argo          resilience-bench-ptngm-run-health-check-1168793163      0/2     Completed   0               3d7h   192.168.221.67    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,596 [INFO]   argo          resilience-bench-ptngm-run-health-check-1185570782      0/2     Completed   0               3d7h   192.168.221.66    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,596 [INFO]   argo          resilience-bench-ptngm-run-health-check-1202348401      0/2     Completed   0               3d7h   192.168.221.122   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,596 [INFO]   argo          resilience-bench-wf87f-initialize-metrics-3677018408    0/2     Completed   0               3d9h   192.168.221.100   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,596 [INFO]   argo          resilience-bench-wf87f-run-health-check-2914150102      0/2     Completed   0               3d9h   192.168.221.105   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,596 [INFO]   argo          resilience-bench-wf87f-run-health-check-3931060015      0/2     Completed   0               3d9h   192.168.221.104   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,597 [INFO]   argo          resilience-bench-wf87f-run-health-check-3947837634      0/2     Completed   0               3d9h   192.168.221.98    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,597 [INFO]   argo          resilience-bench-wf87f-run-health-check-3964615253      0/2     Completed   0               3d9h   192.168.221.103   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,597 [INFO]   argo          resilience-bench-wf87f-run-node-simulation-4173146970   0/2     Completed   0               3d9h   192.168.221.101   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,597 [INFO]   argo          resilience-bench-wf87f-run-rack-simulation-1356070019   0/2     Completed   0               3d9h   192.168.221.109   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,597 [INFO]   argo          resilience-heft-4cqbx-health-check-1589398418           0/2     Error       0               16h    192.168.15.231    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,597 [INFO]   argo          resilience-heft-4cqbx-heft-initialize-2594215169        0/2     Completed   0               16h    192.168.221.79    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,597 [INFO]   argo          resilience-heft-76kbp-health-check-270747540            0/2     Error       0               16h    192.168.15.237    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,597 [INFO]   argo          resilience-heft-76kbp-heft-initialize-3574960751        0/2     Completed   0               16h    192.168.221.86    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,597 [INFO]   argo          resilience-heft-b85xr-health-check-2840770649           0/2     Error       0               16h    192.168.15.240    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,601 [INFO]   argo          resilience-heft-b85xr-heft-initialize-1754406316        0/2     Completed   0               16h    192.168.221.88    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,601 [INFO]   argo          resilience-heft-fdw9f-health-check-1896357264           0/2     Error       0               16h    192.168.15.235    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,601 [INFO]   argo          resilience-heft-fdw9f-heft-initialize-2651619139        0/2     Completed   0               16h    192.168.221.77    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,601 [INFO]   argo          resilience-heft-gf256-health-check-980174358            0/2     Error       0               16h    192.168.15.236    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,602 [INFO]   argo          resilience-heft-gf256-heft-initialize-1548293021        0/2     Completed   0               16h    192.168.221.84    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,602 [INFO]   argo          resilience-heft-gxwpg-health-check-3445304423           0/2     Error       0               16h    192.168.15.233    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,602 [INFO]   argo          resilience-heft-gxwpg-heft-initialize-2377397022        0/2     Completed   0               16h    192.168.221.81    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,602 [INFO]   argo          resilience-heft-jx8fh-health-check-3032273300           2/2     Running     0               19s    192.168.221.72    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,602 [INFO]   argo          resilience-heft-jx8fh-health-check-3049050919           2/2     Running     0               19s    192.168.221.76    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,602 [INFO]   argo          resilience-heft-jx8fh-health-check-3065828538           2/2     Running     0               19s    192.168.221.74    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,602 [INFO]   argo          resilience-heft-jx8fh-heft-initialize-4056367215        0/2     Completed   0               29s    192.168.221.73    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,602 [INFO]   argo          resilience-heft-pc2kb-health-check-3258812212           0/2     Error       0               16h    192.168.15.238    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,603 [INFO]   argo          resilience-heft-pc2kb-heft-initialize-321333135         0/2     Completed   0               16h    192.168.221.83    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,603 [INFO]   argo          resilience-heft-qsmch-health-check-283908068            0/2     Error       0               16h    192.168.15.232    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,603 [INFO]   argo          resilience-heft-qsmch-heft-initialize-1908810015        0/2     Completed   0               16h    192.168.221.82    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,603 [INFO]   argo          resilience-heft-r2w8l-health-check-366927355            0/2     Error       0               16h    192.168.15.239    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,603 [INFO]   argo          resilience-heft-r2w8l-heft-initialize-3054048250        0/2     Completed   0               16h    192.168.221.85    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,603 [INFO]   argo          resilience-heft-t988k-health-check-612195296            0/2     Error       0               16h    192.168.15.234    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,603 [INFO]   argo          resilience-heft-t988k-heft-initialize-164752883         0/2     Completed   0               16h    192.168.221.80    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,603 [INFO]   argo          resilience-heft-vlt2m-health-check-2709447919           0/2     Error       0               15h    192.168.221.119   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,603 [INFO]   argo          resilience-heft-vlt2m-health-check-2726225538           0/2     Error       0               15h    192.168.221.120   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,603 [INFO]   argo          resilience-heft-vlt2m-health-check-2743003157           0/2     Error       0               15h    192.168.221.121   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,604 [INFO]   argo          resilience-heft-vlt2m-heft-initialize-840404112         0/2     Completed   0               15h    192.168.221.118   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,604 [INFO]   argo          resilience-heft-x86wd-health-check-2184182048           0/2     Error       0               15h    192.168.221.123   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,604 [INFO]   argo          resilience-heft-x86wd-health-check-2200959667           0/2     Error       0               15h    192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,604 [INFO]   argo          resilience-heft-x86wd-health-check-2234514905           0/2     Error       0               15h    192.168.221.124   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,604 [INFO]   argo          resilience-heft-x86wd-heft-initialize-2152040770        0/2     Completed   0               15h    192.168.221.127   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,604 [INFO]   argo          workflow-controller-ccbd949dc-t4rx9                     1/1     Running     1 (116m ago)    15h    192.168.195.243   worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,604 [INFO]   kube-system   calico-kube-controllers-7498b9bb4c-xd7tb                1/1     Running     0               2d5h   192.168.191.108   worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,604 [INFO]   kube-system   calico-node-4zhd4                                       1/1     Running     0               11d    192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,604 [INFO]   kube-system   calico-node-75nx6                                       1/1     Running     0               11d    192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,607 [INFO]   kube-system   calico-node-7lkdq                                       1/1     Running     0               11d    192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,607 [INFO]   kube-system   calico-node-85f8c                                       1/1     Running     0               11d    192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,607 [INFO]   kube-system   calico-node-j8nb9                                       1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,608 [INFO]   kube-system   calico-node-lbcb2                                       1/1     Running     0               11d    192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,608 [INFO]   kube-system   calico-node-wlr5v                                       1/1     Running     0               11d    192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,608 [INFO]   kube-system   calico-node-xnzjw                                       1/1     Running     0               11d    192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,608 [INFO]   kube-system   calico-node-xsltn                                       1/1     Running     0               11d    192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,608 [INFO]   kube-system   coredns-668d6bf9bc-2f74f                                1/1     Running     0               2d6h   192.168.15.230    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,608 [INFO]   kube-system   coredns-668d6bf9bc-qnzjq                                1/1     Running     0               14h    192.168.132.176   worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,609 [INFO]   kube-system   etcd-master-m001                                        1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,609 [INFO]   kube-system   kube-apiserver-master-m001                              1/1     Running     1 (3d2h ago)    11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,609 [INFO]   kube-system   kube-controller-manager-master-m001                     1/1     Running     13 (115m ago)   11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,609 [INFO]   kube-system   kube-proxy-5lzhj                                        1/1     Running     0               11d    192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,609 [INFO]   kube-system   kube-proxy-7jqkv                                        1/1     Running     0               11d    192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,609 [INFO]   kube-system   kube-proxy-cv5dt                                        1/1     Running     0               11d    192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,609 [INFO]   kube-system   kube-proxy-fvpmr                                        1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,609 [INFO]   kube-system   kube-proxy-hgs5z                                        1/1     Running     0               11d    192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,609 [INFO]   kube-system   kube-proxy-kmgqr                                        1/1     Running     0               11d    192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,609 [INFO]   kube-system   kube-proxy-rdbz5                                        1/1     Running     0               11d    192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,609 [INFO]   kube-system   kube-proxy-w8mnb                                        1/1     Running     0               11d    192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,610 [INFO]   kube-system   kube-proxy-x9jxr                                        1/1     Running     0               11d    192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,610 [INFO]   kube-system   kube-scheduler-master-m001                              1/1     Running     12 (115m ago)   11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,610 [INFO] [0m
[36mresilience-heft-jx8fh-health-check-3032273300: Pod distribution by node:[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,667 [INFO]   worker-w006     Ready  ‚úì worker         R3    No       None [0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,669 [INFO] [0m
[35mresilience-heft-jx8fh-health-check-3049050919: Legend:[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,669 [INFO]   ‚úì = Node is Ready[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,670 [INFO]   ‚ö†Ô∏è = Warning indicator (NotReady, Cordoned, or has simulated-failure taint)[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,670 [INFO] ============ DETAILED POD INFORMATION ============[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,670 [INFO] Running 'kubectl get pods -o wide' to show detailed pod placement:[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,824 [INFO]   Node master-m003: 36 pods[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,824 [INFO]   Node worker-w005: 13 pods[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,824 [INFO]   Node 15h: 1 pods[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,824 [INFO]   Node worker-w006: 3 pods[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,824 [INFO]   Node worker-w002: 2 pods[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,824 [INFO]   Node worker-w001: 3 pods[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,824 [INFO]   Node master-m002: 2 pods[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,825 [INFO]   Node master-m001: 3 pods[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,825 [INFO]   Node worker-w003: 2 pods[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,825 [INFO]   Node worker-w004: 2 pods[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,825 [INFO]   Node 11d: 3 pods[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:46,825 [INFO] [0m
[36mresilience-heft-jx8fh-health-check-3032273300: Filtering for simulation services:[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,857 [INFO]   Node master-m003: 36 pods[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,857 [INFO]   Node worker-w005: 13 pods[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,857 [INFO]   Node 15h: 1 pods[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,857 [INFO]   Node worker-w006: 3 pods[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,857 [INFO]   Node worker-w002: 2 pods[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,857 [INFO]   Node worker-w001: 3 pods[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,857 [INFO]   Node master-m002: 2 pods[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,857 [INFO]   Node master-m001: 3 pods[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,857 [INFO]   Node worker-w003: 2 pods[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,857 [INFO]   Node worker-w004: 2 pods[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,857 [INFO]   Node 11d: 3 pods[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:46,857 [INFO] [0m
[37mresilience-heft-jx8fh-health-check-3065828538: Filtering for simulation services:[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,929 [INFO]   NAMESPACE     NAME                                                    READY   STATUS      RESTARTS        AGE    IP                NODE          NOMINATED NODE   READINESS GATES[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          argo-server-5c69cb69db-gdkl6                            1/1     Running     0               8d     192.168.221.65    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-bench-ptngm-initialize-metrics-940927476     0/2     Completed   0               3d7h   192.168.221.125   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-bench-ptngm-run-health-check-1168793163      0/2     Completed   0               3d7h   192.168.221.67    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-bench-ptngm-run-health-check-1185570782      0/2     Completed   0               3d7h   192.168.221.66    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-bench-ptngm-run-health-check-1202348401      0/2     Completed   0               3d7h   192.168.221.122   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-bench-wf87f-initialize-metrics-3677018408    0/2     Completed   0               3d9h   192.168.221.100   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-bench-wf87f-run-health-check-2914150102      0/2     Completed   0               3d9h   192.168.221.105   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-bench-wf87f-run-health-check-3931060015      0/2     Completed   0               3d9h   192.168.221.104   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-bench-wf87f-run-health-check-3947837634      0/2     Completed   0               3d9h   192.168.221.98    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-bench-wf87f-run-health-check-3964615253      0/2     Completed   0               3d9h   192.168.221.103   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-bench-wf87f-run-node-simulation-4173146970   0/2     Completed   0               3d9h   192.168.221.101   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-bench-wf87f-run-rack-simulation-1356070019   0/2     Completed   0               3d9h   192.168.221.109   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-heft-4cqbx-health-check-1589398418           0/2     Error       0               16h    192.168.15.231    worker-w005   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-heft-4cqbx-heft-initialize-2594215169        0/2     Completed   0               16h    192.168.221.79    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-heft-76kbp-health-check-270747540            0/2     Error       0               16h    192.168.15.237    worker-w005   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-heft-76kbp-heft-initialize-3574960751        0/2     Completed   0               16h    192.168.221.86    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-heft-b85xr-health-check-2840770649           0/2     Error       0               16h    192.168.15.240    worker-w005   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-heft-b85xr-heft-initialize-1754406316        0/2     Completed   0               16h    192.168.221.88    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-heft-fdw9f-health-check-1896357264           0/2     Error       0               16h    192.168.15.235    worker-w005   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-heft-fdw9f-heft-initialize-2651619139        0/2     Completed   0               16h    192.168.221.77    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-heft-gf256-health-check-980174358            0/2     Error       0               16h    192.168.15.236    worker-w005   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-heft-gf256-heft-initialize-1548293021        0/2     Completed   0               16h    192.168.221.84    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-heft-gxwpg-health-check-3445304423           0/2     Error       0               16h    192.168.15.233    worker-w005   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,930 [INFO]   argo          resilience-heft-gxwpg-heft-initialize-2377397022        0/2     Completed   0               16h    192.168.221.81    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-jx8fh-health-check-3032273300           2/2     Running     0               19s    192.168.221.72    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-jx8fh-health-check-3049050919           2/2     Running     0               19s    192.168.221.76    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-jx8fh-health-check-3065828538           2/2     Running     0               19s    192.168.221.74    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-jx8fh-heft-initialize-4056367215        0/2     Completed   0               29s    192.168.221.73    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-pc2kb-health-check-3258812212           0/2     Error       0               16h    192.168.15.238    worker-w005   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-pc2kb-heft-initialize-321333135         0/2     Completed   0               16h    192.168.221.83    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-qsmch-health-check-283908068            0/2     Error       0               16h    192.168.15.232    worker-w005   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-qsmch-heft-initialize-1908810015        0/2     Completed   0               16h    192.168.221.82    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-r2w8l-health-check-366927355            0/2     Error       0               16h    192.168.15.239    worker-w005   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-r2w8l-heft-initialize-3054048250        0/2     Completed   0               16h    192.168.221.85    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-t988k-health-check-612195296            0/2     Error       0               16h    192.168.15.234    worker-w005   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-t988k-heft-initialize-164752883         0/2     Completed   0               16h    192.168.221.80    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-vlt2m-health-check-2709447919           0/2     Error       0               15h    192.168.221.119   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-vlt2m-health-check-2726225538           0/2     Error       0               15h    192.168.221.120   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-vlt2m-health-check-2743003157           0/2     Error       0               15h    192.168.221.121   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-vlt2m-heft-initialize-840404112         0/2     Completed   0               15h    192.168.221.118   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-x86wd-health-check-2184182048           0/2     Error       0               15h    192.168.221.123   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-x86wd-health-check-2200959667           0/2     Error       0               15h    192.168.221.125   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-x86wd-health-check-2234514905           0/2     Error       0               15h    192.168.221.124   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          resilience-heft-x86wd-heft-initialize-2152040770        0/2     Completed   0               15h    192.168.221.127   master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   argo          workflow-controller-ccbd949dc-t4rx9                     1/1     Running     1 (116m ago)    15h    192.168.195.243   worker-w002   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   kube-system   calico-kube-controllers-7498b9bb4c-xd7tb                1/1     Running     0               2d5h   192.168.191.108   worker-w006   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   kube-system   calico-node-4zhd4                                       1/1     Running     0               11d    192.168.56.105    worker-w002   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   kube-system   calico-node-75nx6                                       1/1     Running     0               11d    192.168.56.109    worker-w006   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   kube-system   calico-node-7lkdq                                       1/1     Running     0               11d    192.168.56.104    worker-w001   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   kube-system   calico-node-85f8c                                       1/1     Running     0               11d    192.168.56.102    master-m002   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   kube-system   calico-node-j8nb9                                       1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   kube-system   calico-node-lbcb2                                       1/1     Running     0               11d    192.168.56.106    worker-w003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   kube-system   calico-node-wlr5v                                       1/1     Running     0               11d    192.168.56.107    worker-w004   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   kube-system   calico-node-xnzjw                                       1/1     Running     0               11d    192.168.56.103    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   kube-system   calico-node-xsltn                                       1/1     Running     0               11d    192.168.56.108    worker-w005   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,931 [INFO]   kube-system   coredns-668d6bf9bc-2f74f                                1/1     Running     0               2d6h   192.168.15.230    worker-w005   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   coredns-668d6bf9bc-qnzjq                                1/1     Running     0               14h    192.168.132.176   worker-w001   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   etcd-master-m001                                        1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   kube-apiserver-master-m001                              1/1     Running     1 (3d2h ago)    11d    192.168.56.101    master-m001   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   kube-controller-manager-master-m001                     1/1     Running     13 (115m ago)   11d    192.168.56.101    master-m001   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   kube-proxy-5lzhj                                        1/1     Running     0               11d    192.168.56.102    master-m002   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   kube-proxy-7jqkv                                        1/1     Running     0               11d    192.168.56.109    worker-w006   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   kube-proxy-cv5dt                                        1/1     Running     0               11d    192.168.56.108    worker-w005   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   kube-proxy-fvpmr                                        1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   kube-proxy-hgs5z                                        1/1     Running     0               11d    192.168.56.106    worker-w003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   kube-proxy-kmgqr                                        1/1     Running     0               11d    192.168.56.105    worker-w002   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   kube-proxy-rdbz5                                        1/1     Running     0               11d    192.168.56.107    worker-w004   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   kube-proxy-w8mnb                                        1/1     Running     0               11d    192.168.56.103    master-m003   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   kube-proxy-x9jxr                                        1/1     Running     0               11d    192.168.56.104    worker-w001   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO]   kube-system   kube-scheduler-master-m001                              1/1     Running     12 (115m ago)   11d    192.168.56.101    master-m001   <none>           <none>[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:46,932 [INFO] [0m
[35mresilience-heft-jx8fh-health-check-3049050919: Pod distribution by node:[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,054 [INFO]   Node master-m003: 36 pods[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,054 [INFO]   Node worker-w005: 13 pods[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,054 [INFO]   Node 15h: 1 pods[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,054 [INFO]   Node worker-w006: 3 pods[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,054 [INFO]   Node worker-w002: 2 pods[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,054 [INFO]   Node worker-w001: 3 pods[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,054 [INFO]   Node master-m002: 2 pods[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,054 [INFO]   Node master-m001: 3 pods[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,054 [INFO]   Node worker-w003: 2 pods[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,054 [INFO]   Node worker-w004: 2 pods[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,054 [INFO]   Node 11d: 3 pods[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,055 [INFO] [0m
[35mresilience-heft-jx8fh-health-check-3049050919: Filtering for simulation services:[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,202 [INFO] Node master-m001 is Ready[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,205 [INFO] Node master-m002 is Ready[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,205 [INFO] Node master-m003 is Ready[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,205 [INFO] Node worker-w001 is Ready[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,205 [INFO] Node worker-w002 is Ready[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,205 [INFO] Node worker-w003 is Ready[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,206 [INFO] Node worker-w004 is Ready[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,206 [INFO] Node worker-w005 is Ready[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,206 [INFO] Node worker-w006 is Ready[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,209 [WARNING] No pods found for etcd-sim[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,214 [INFO] Node master-m001 is Ready[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,215 [INFO] Node master-m002 is Ready[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,215 [INFO] Node master-m003 is Ready[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,215 [INFO] Node worker-w001 is Ready[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,216 [INFO] Node worker-w002 is Ready[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,216 [INFO] Node worker-w003 is Ready[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,216 [INFO] Node worker-w004 is Ready[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,217 [INFO] Node worker-w005 is Ready[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,217 [INFO] Node worker-w006 is Ready[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,218 [WARNING] No pods found for postgres-sim[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,221 [WARNING] No pods found for redis-sim[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,223 [WARNING] No pods found for etcd-sim[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,224 [WARNING] No pods found for nginx-sim[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,227 [WARNING] No pods found for postgres-sim[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,229 [WARNING] No pods found for auth-sim[0m
[37mresilience-heft-jx8fh-health-check-3065828538: 2026-01-06 05:51:47,229 [INFO] Completed full health check[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,231 [WARNING] No pods found for redis-sim[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,233 [WARNING] No pods found for nginx-sim[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,235 [WARNING] No pods found for auth-sim[0m
[36mresilience-heft-jx8fh-health-check-3032273300: 2026-01-06 05:51:47,235 [INFO] Completed full health check[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,258 [INFO] Node master-m001 is Ready[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,258 [INFO] Node master-m002 is Ready[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,258 [INFO] Node master-m003 is Ready[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,258 [INFO] Node worker-w001 is Ready[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,258 [INFO] Node worker-w002 is Ready[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,258 [INFO] Node worker-w003 is Ready[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,258 [INFO] Node worker-w004 is Ready[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,258 [INFO] Node worker-w005 is Ready[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,258 [INFO] Node worker-w006 is Ready[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,262 [WARNING] No pods found for etcd-sim[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,281 [WARNING] No pods found for postgres-sim[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,285 [WARNING] No pods found for redis-sim[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,291 [WARNING] No pods found for nginx-sim[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,294 [WARNING] No pods found for auth-sim[0m
[35mresilience-heft-jx8fh-health-check-3049050919: 2026-01-06 05:51:47,294 [INFO] Completed full health check[0m
[36mresilience-heft-jx8fh-health-check-3032273300: time="2026-01-06T05:51:47.343Z" level=info msg="sub-process exited" argo=true error="<nil>"[0m
[35mresilience-heft-jx8fh-health-check-3049050919: time="2026-01-06T05:51:47.703Z" level=info msg="sub-process exited" argo=true error="<nil>"[0m
[37mresilience-heft-jx8fh-health-check-3065828538: time="2026-01-06T05:51:47.889Z" level=info msg="sub-process exited" argo=true error="<nil>"[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: Log directory created/verified: /app/logs[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: File logging configured successfully[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,147 [INFO] Loaded in-cluster Kubernetes config[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,148 [INFO] Running on host: resilience-heft-jx8fh-node-failure-sim-2830132693[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,148 [INFO] Detected current node: master-m003, zone: R3[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,148 [INFO] Checking if we have permissions to modify nodes...[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,184 [INFO] Testing permissions using node: master-m001[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,192 [INFO] Permission check successful - we can modify nodes[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,192 [INFO] Using real Kubernetes API for node control[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,193 [INFO] Action received: simulate-node[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,193 [INFO] Stabilization time: 60 seconds[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,193 [INFO] Simulating node failure: worker-w003[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,194 [INFO] Simulating node failure for worker-w003 using Kubernetes API[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,207 [INFO] Node worker-w003 cordoned[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,232 [INFO] Node worker-w003 tainted with NoExecute[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,232 [INFO] Node worker-w003 powered off (delay 5s)[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,233 [INFO] Node worker-w003 down for 10 seconds[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:52:09,233 [INFO] Waiting 60 seconds for the cluster to stabilize before health check...[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,291 [INFO] Running health check after node power off[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,291 [INFO] Starting full health check[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,291 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: ============ DETAILED NODE STATUS ============[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,291 [INFO] Basic Node Information (kubectl get nodes -o wide):[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,363 [INFO]   NAME          STATUS                     ROLES           AGE   VERSION    INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,363 [INFO]   master-m001   Ready                      control-plane   11d   v1.32.11   192.168.56.101   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,363 [INFO]   master-m002   Ready                      control-plane   11d   v1.32.11   192.168.56.102   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,363 [INFO]   master-m003   Ready                      control-plane   11d   v1.32.11   192.168.56.103   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,363 [INFO]   worker-w001   Ready                      <none>          11d   v1.32.11   192.168.56.104   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,363 [INFO]   worker-w002   Ready                      <none>          11d   v1.32.11   192.168.56.105   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,363 [INFO]   worker-w003   Ready,SchedulingDisabled   <none>          11d   v1.32.11   192.168.56.106   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,364 [INFO]   worker-w004   Ready                      <none>          11d   v1.32.11   192.168.56.107   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,364 [INFO]   worker-w005   Ready                      <none>          11d   v1.32.11   192.168.56.108   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,364 [INFO]   worker-w006   Ready                      <none>          11d   v1.32.11   192.168.56.109   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,364 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: Enhanced Node Status (with taint and cordon indicators):[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,364 [INFO]   NAME                STATUS    ROLES           ZONE   CORDONED   TAINTS[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,615 [INFO]   master-m001     Ready  ‚úì worker         R1    No       node-role.kubernetes.io/control-plane [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:09,834 [INFO]   master-m002     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:10,010 [INFO]   master-m003     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:10,211 [INFO]   worker-w001     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:10,444 [INFO]   worker-w002     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:10,688 [INFO]   worker-w003     Ready  ‚úì worker         R2    YES     ‚ö†Ô∏è simulated-failure, node.kubernetes.io/unschedulable ‚ö†Ô∏è[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:10,870 [INFO]   worker-w004     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,060 [INFO]   worker-w005     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,229 [INFO]   worker-w006     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,229 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: Legend:[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,229 [INFO]   ‚úì = Node is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,229 [INFO]   ‚ö†Ô∏è = Warning indicator (NotReady, Cordoned, or has simulated-failure taint)[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,230 [INFO] ============ DETAILED POD INFORMATION ============[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,230 [INFO] Running 'kubectl get pods -o wide' to show detailed pod placement:[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,309 [INFO]   NAMESPACE     NAME                                                    READY   STATUS      RESTARTS        AGE    IP                NODE          NOMINATED NODE   READINESS GATES[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,309 [INFO]   argo          argo-server-5c69cb69db-gdkl6                            1/1     Running     0               8d     192.168.221.65    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,309 [INFO]   argo          resilience-bench-ptngm-initialize-metrics-940927476     0/2     Completed   0               3d7h   192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,310 [INFO]   argo          resilience-bench-ptngm-run-health-check-1168793163      0/2     Completed   0               3d7h   192.168.221.67    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,310 [INFO]   argo          resilience-bench-ptngm-run-health-check-1185570782      0/2     Completed   0               3d7h   192.168.221.66    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,310 [INFO]   argo          resilience-bench-ptngm-run-health-check-1202348401      0/2     Completed   0               3d7h   192.168.221.122   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,310 [INFO]   argo          resilience-bench-wf87f-initialize-metrics-3677018408    0/2     Completed   0               3d9h   192.168.221.100   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,310 [INFO]   argo          resilience-bench-wf87f-run-health-check-2914150102      0/2     Completed   0               3d9h   192.168.221.105   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,310 [INFO]   argo          resilience-bench-wf87f-run-health-check-3931060015      0/2     Completed   0               3d9h   192.168.221.104   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,310 [INFO]   argo          resilience-bench-wf87f-run-health-check-3947837634      0/2     Completed   0               3d9h   192.168.221.98    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,310 [INFO]   argo          resilience-bench-wf87f-run-health-check-3964615253      0/2     Completed   0               3d9h   192.168.221.103   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,310 [INFO]   argo          resilience-bench-wf87f-run-node-simulation-4173146970   0/2     Completed   0               3d9h   192.168.221.101   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,311 [INFO]   argo          resilience-bench-wf87f-run-rack-simulation-1356070019   0/2     Completed   0               3d9h   192.168.221.109   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,311 [INFO]   argo          resilience-heft-4cqbx-health-check-1589398418           0/2     Error       0               16h    192.168.15.231    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,311 [INFO]   argo          resilience-heft-4cqbx-heft-initialize-2594215169        0/2     Completed   0               16h    192.168.221.79    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,311 [INFO]   argo          resilience-heft-76kbp-health-check-270747540            0/2     Error       0               16h    192.168.15.237    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,311 [INFO]   argo          resilience-heft-76kbp-heft-initialize-3574960751        0/2     Completed   0               16h    192.168.221.86    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,311 [INFO]   argo          resilience-heft-b85xr-health-check-2840770649           0/2     Error       0               16h    192.168.15.240    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,311 [INFO]   argo          resilience-heft-b85xr-heft-initialize-1754406316        0/2     Completed   0               16h    192.168.221.88    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,311 [INFO]   argo          resilience-heft-fdw9f-health-check-1896357264           0/2     Error       0               16h    192.168.15.235    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,311 [INFO]   argo          resilience-heft-fdw9f-heft-initialize-2651619139        0/2     Completed   0               16h    192.168.221.77    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,311 [INFO]   argo          resilience-heft-gf256-health-check-980174358            0/2     Error       0               16h    192.168.15.236    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,311 [INFO]   argo          resilience-heft-gf256-heft-initialize-1548293021        0/2     Completed   0               16h    192.168.221.84    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,312 [INFO]   argo          resilience-heft-gxwpg-health-check-3445304423           0/2     Error       0               16h    192.168.15.233    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,312 [INFO]   argo          resilience-heft-gxwpg-heft-initialize-2377397022        0/2     Completed   0               16h    192.168.221.81    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,312 [INFO]   argo          resilience-heft-jx8fh-health-check-3032273300           0/2     Completed   0               104s   192.168.221.72    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,312 [INFO]   argo          resilience-heft-jx8fh-health-check-3049050919           0/2     Completed   0               104s   192.168.221.76    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,312 [INFO]   argo          resilience-heft-jx8fh-health-check-3065828538           0/2     Completed   0               104s   192.168.221.74    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,312 [INFO]   argo          resilience-heft-jx8fh-heft-initialize-4056367215        0/2     Completed   0               114s   192.168.221.73    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,312 [INFO]   argo          resilience-heft-jx8fh-node-failure-sim-2830132693       2/2     Running     0               72s    192.168.221.75    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,312 [INFO]   argo          resilience-heft-pc2kb-health-check-3258812212           0/2     Error       0               16h    192.168.15.238    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,312 [INFO]   argo          resilience-heft-pc2kb-heft-initialize-321333135         0/2     Completed   0               16h    192.168.221.83    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,312 [INFO]   argo          resilience-heft-qsmch-health-check-283908068            0/2     Error       0               16h    192.168.15.232    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,313 [INFO]   argo          resilience-heft-qsmch-heft-initialize-1908810015        0/2     Completed   0               16h    192.168.221.82    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,313 [INFO]   argo          resilience-heft-r2w8l-health-check-366927355            0/2     Error       0               16h    192.168.15.239    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,313 [INFO]   argo          resilience-heft-r2w8l-heft-initialize-3054048250        0/2     Completed   0               16h    192.168.221.85    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,313 [INFO]   argo          resilience-heft-t988k-health-check-612195296            0/2     Error       0               16h    192.168.15.234    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,313 [INFO]   argo          resilience-heft-t988k-heft-initialize-164752883         0/2     Completed   0               16h    192.168.221.80    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,313 [INFO]   argo          resilience-heft-vlt2m-health-check-2709447919           0/2     Error       0               15h    192.168.221.119   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,313 [INFO]   argo          resilience-heft-vlt2m-health-check-2726225538           0/2     Error       0               15h    192.168.221.120   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,313 [INFO]   argo          resilience-heft-vlt2m-health-check-2743003157           0/2     Error       0               15h    192.168.221.121   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,313 [INFO]   argo          resilience-heft-vlt2m-heft-initialize-840404112         0/2     Completed   0               15h    192.168.221.118   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,313 [INFO]   argo          resilience-heft-x86wd-health-check-2184182048           0/2     Error       0               15h    192.168.221.123   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,314 [INFO]   argo          resilience-heft-x86wd-health-check-2200959667           0/2     Error       0               15h    192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,314 [INFO]   argo          resilience-heft-x86wd-health-check-2234514905           0/2     Error       0               15h    192.168.221.124   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,314 [INFO]   argo          resilience-heft-x86wd-heft-initialize-2152040770        0/2     Completed   0               15h    192.168.221.127   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,314 [INFO]   argo          workflow-controller-ccbd949dc-t4rx9                     1/1     Running     1 (117m ago)    15h    192.168.195.243   worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,314 [INFO]   kube-system   calico-kube-controllers-7498b9bb4c-xd7tb                1/1     Running     0               2d5h   192.168.191.108   worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,314 [INFO]   kube-system   calico-node-4zhd4                                       1/1     Running     0               11d    192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,314 [INFO]   kube-system   calico-node-75nx6                                       1/1     Running     0               11d    192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,314 [INFO]   kube-system   calico-node-7lkdq                                       1/1     Running     0               11d    192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,315 [INFO]   kube-system   calico-node-85f8c                                       1/1     Running     0               11d    192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,315 [INFO]   kube-system   calico-node-j8nb9                                       1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,315 [INFO]   kube-system   calico-node-lbcb2                                       1/1     Running     0               11d    192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,315 [INFO]   kube-system   calico-node-wlr5v                                       1/1     Running     0               11d    192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,315 [INFO]   kube-system   calico-node-xnzjw                                       1/1     Running     0               11d    192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,315 [INFO]   kube-system   calico-node-xsltn                                       1/1     Running     0               11d    192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,316 [INFO]   kube-system   coredns-668d6bf9bc-2f74f                                1/1     Running     0               2d6h   192.168.15.230    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,316 [INFO]   kube-system   coredns-668d6bf9bc-qnzjq                                1/1     Running     0               14h    192.168.132.176   worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,316 [INFO]   kube-system   etcd-master-m001                                        1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,316 [INFO]   kube-system   kube-apiserver-master-m001                              1/1     Running     1 (3d2h ago)    11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,316 [INFO]   kube-system   kube-controller-manager-master-m001                     1/1     Running     13 (117m ago)   11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,316 [INFO]   kube-system   kube-proxy-5lzhj                                        1/1     Running     0               11d    192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,316 [INFO]   kube-system   kube-proxy-7jqkv                                        1/1     Running     0               11d    192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,316 [INFO]   kube-system   kube-proxy-cv5dt                                        1/1     Running     0               11d    192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,316 [INFO]   kube-system   kube-proxy-fvpmr                                        1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,316 [INFO]   kube-system   kube-proxy-hgs5z                                        1/1     Running     0               11d    192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,317 [INFO]   kube-system   kube-proxy-kmgqr                                        1/1     Running     0               11d    192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,317 [INFO]   kube-system   kube-proxy-rdbz5                                        1/1     Running     0               11d    192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,317 [INFO]   kube-system   kube-proxy-w8mnb                                        1/1     Running     0               11d    192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,317 [INFO]   kube-system   kube-proxy-x9jxr                                        1/1     Running     0               11d    192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,317 [INFO]   kube-system   kube-scheduler-master-m001                              1/1     Running     12 (117m ago)   11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,317 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: Pod distribution by node:[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,403 [INFO]   Node master-m003: 37 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,404 [INFO]   Node worker-w005: 13 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,404 [INFO]   Node 15h: 1 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,404 [INFO]   Node worker-w006: 3 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,404 [INFO]   Node worker-w002: 2 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,404 [INFO]   Node worker-w001: 3 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,404 [INFO]   Node master-m002: 2 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,404 [INFO]   Node master-m001: 3 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,404 [INFO]   Node worker-w003: 2 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,404 [INFO]   Node worker-w004: 2 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,404 [INFO]   Node 11d: 3 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,404 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: Filtering for simulation services:[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,610 [INFO] Node master-m001 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,610 [INFO] Node master-m002 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,610 [INFO] Node master-m003 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,611 [INFO] Node worker-w001 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,611 [INFO] Node worker-w002 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,611 [INFO] Node worker-w003 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,611 [INFO] Node worker-w004 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,611 [INFO] Node worker-w005 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,611 [INFO] Node worker-w006 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,615 [WARNING] No pods found for etcd-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,616 [WARNING] No pods found for postgres-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,618 [WARNING] No pods found for redis-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,620 [WARNING] No pods found for nginx-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,622 [WARNING] No pods found for auth-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:11,622 [INFO] Completed full health check[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,633 [INFO] Running health check before node power on[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,634 [INFO] Starting full health check[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,634 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: ============ DETAILED NODE STATUS ============[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,634 [INFO] Basic Node Information (kubectl get nodes -o wide):[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,704 [INFO]   NAME          STATUS                     ROLES           AGE   VERSION    INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,704 [INFO]   master-m001   Ready                      control-plane   11d   v1.32.11   192.168.56.101   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,704 [INFO]   master-m002   Ready                      control-plane   11d   v1.32.11   192.168.56.102   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,704 [INFO]   master-m003   Ready                      control-plane   11d   v1.32.11   192.168.56.103   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,705 [INFO]   worker-w001   Ready                      <none>          11d   v1.32.11   192.168.56.104   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,705 [INFO]   worker-w002   Ready                      <none>          11d   v1.32.11   192.168.56.105   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,705 [INFO]   worker-w003   Ready,SchedulingDisabled   <none>          11d   v1.32.11   192.168.56.106   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,705 [INFO]   worker-w004   Ready                      <none>          11d   v1.32.11   192.168.56.107   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,705 [INFO]   worker-w005   Ready                      <none>          11d   v1.32.11   192.168.56.108   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,705 [INFO]   worker-w006   Ready                      <none>          11d   v1.32.11   192.168.56.109   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,705 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: Enhanced Node Status (with taint and cordon indicators):[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:21,705 [INFO]   NAME                STATUS    ROLES           ZONE   CORDONED   TAINTS[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:22,011 [INFO]   master-m001     Ready  ‚úì worker         R1    No       node-role.kubernetes.io/control-plane [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:22,213 [INFO]   master-m002     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:22,399 [INFO]   master-m003     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:22,590 [INFO]   worker-w001     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:22,773 [INFO]   worker-w002     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:22,962 [INFO]   worker-w003     Ready  ‚úì worker         R2    YES     ‚ö†Ô∏è simulated-failure, node.kubernetes.io/unschedulable ‚ö†Ô∏è[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,110 [INFO]   worker-w004     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,245 [INFO]   worker-w005     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,395 [INFO]   worker-w006     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,396 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: Legend:[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,396 [INFO]   ‚úì = Node is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,396 [INFO]   ‚ö†Ô∏è = Warning indicator (NotReady, Cordoned, or has simulated-failure taint)[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,396 [INFO] ============ DETAILED POD INFORMATION ============[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,396 [INFO] Running 'kubectl get pods -o wide' to show detailed pod placement:[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,479 [INFO]   NAMESPACE     NAME                                                    READY   STATUS      RESTARTS        AGE    IP                NODE          NOMINATED NODE   READINESS GATES[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,479 [INFO]   argo          argo-server-5c69cb69db-gdkl6                            1/1     Running     0               8d     192.168.221.65    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,479 [INFO]   argo          resilience-bench-ptngm-initialize-metrics-940927476     0/2     Completed   0               3d7h   192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,479 [INFO]   argo          resilience-bench-ptngm-run-health-check-1168793163      0/2     Completed   0               3d7h   192.168.221.67    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,479 [INFO]   argo          resilience-bench-ptngm-run-health-check-1185570782      0/2     Completed   0               3d7h   192.168.221.66    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-bench-ptngm-run-health-check-1202348401      0/2     Completed   0               3d7h   192.168.221.122   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-bench-wf87f-initialize-metrics-3677018408    0/2     Completed   0               3d9h   192.168.221.100   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-bench-wf87f-run-health-check-2914150102      0/2     Completed   0               3d9h   192.168.221.105   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-bench-wf87f-run-health-check-3931060015      0/2     Completed   0               3d9h   192.168.221.104   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-bench-wf87f-run-health-check-3947837634      0/2     Completed   0               3d9h   192.168.221.98    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-bench-wf87f-run-health-check-3964615253      0/2     Completed   0               3d9h   192.168.221.103   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-bench-wf87f-run-node-simulation-4173146970   0/2     Completed   0               3d9h   192.168.221.101   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-bench-wf87f-run-rack-simulation-1356070019   0/2     Completed   0               3d9h   192.168.221.109   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-4cqbx-health-check-1589398418           0/2     Error       0               16h    192.168.15.231    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-4cqbx-heft-initialize-2594215169        0/2     Completed   0               16h    192.168.221.79    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-76kbp-health-check-270747540            0/2     Error       0               16h    192.168.15.237    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-76kbp-heft-initialize-3574960751        0/2     Completed   0               16h    192.168.221.86    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-b85xr-health-check-2840770649           0/2     Error       0               16h    192.168.15.240    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-b85xr-heft-initialize-1754406316        0/2     Completed   0               16h    192.168.221.88    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-fdw9f-health-check-1896357264           0/2     Error       0               16h    192.168.15.235    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-fdw9f-heft-initialize-2651619139        0/2     Completed   0               16h    192.168.221.77    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-gf256-health-check-980174358            0/2     Error       0               16h    192.168.15.236    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-gf256-heft-initialize-1548293021        0/2     Completed   0               16h    192.168.221.84    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-gxwpg-health-check-3445304423           0/2     Error       0               16h    192.168.15.233    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-gxwpg-heft-initialize-2377397022        0/2     Completed   0               16h    192.168.221.81    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-jx8fh-health-check-3032273300           0/2     Completed   0               116s   192.168.221.72    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-jx8fh-health-check-3049050919           0/2     Completed   0               116s   192.168.221.76    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-jx8fh-health-check-3065828538           0/2     Completed   0               116s   192.168.221.74    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,480 [INFO]   argo          resilience-heft-jx8fh-heft-initialize-4056367215        0/2     Completed   0               2m6s   192.168.221.73    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-jx8fh-node-failure-sim-2830132693       2/2     Running     0               84s    192.168.221.75    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-pc2kb-health-check-3258812212           0/2     Error       0               16h    192.168.15.238    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-pc2kb-heft-initialize-321333135         0/2     Completed   0               16h    192.168.221.83    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-qsmch-health-check-283908068            0/2     Error       0               16h    192.168.15.232    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-qsmch-heft-initialize-1908810015        0/2     Completed   0               16h    192.168.221.82    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-r2w8l-health-check-366927355            0/2     Error       0               16h    192.168.15.239    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-r2w8l-heft-initialize-3054048250        0/2     Completed   0               16h    192.168.221.85    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-t988k-health-check-612195296            0/2     Error       0               16h    192.168.15.234    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-t988k-heft-initialize-164752883         0/2     Completed   0               16h    192.168.221.80    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-vlt2m-health-check-2709447919           0/2     Error       0               15h    192.168.221.119   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-vlt2m-health-check-2726225538           0/2     Error       0               15h    192.168.221.120   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-vlt2m-health-check-2743003157           0/2     Error       0               15h    192.168.221.121   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-vlt2m-heft-initialize-840404112         0/2     Completed   0               15h    192.168.221.118   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-x86wd-health-check-2184182048           0/2     Error       0               15h    192.168.221.123   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-x86wd-health-check-2200959667           0/2     Error       0               15h    192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-x86wd-health-check-2234514905           0/2     Error       0               15h    192.168.221.124   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          resilience-heft-x86wd-heft-initialize-2152040770        0/2     Completed   0               15h    192.168.221.127   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   argo          workflow-controller-ccbd949dc-t4rx9                     1/1     Running     1 (117m ago)    15h    192.168.195.243   worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   kube-system   calico-kube-controllers-7498b9bb4c-xd7tb                1/1     Running     0               2d5h   192.168.191.108   worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   kube-system   calico-node-4zhd4                                       1/1     Running     0               11d    192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   kube-system   calico-node-75nx6                                       1/1     Running     0               11d    192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   kube-system   calico-node-7lkdq                                       1/1     Running     0               11d    192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   kube-system   calico-node-85f8c                                       1/1     Running     0               11d    192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   kube-system   calico-node-j8nb9                                       1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   kube-system   calico-node-lbcb2                                       1/1     Running     0               11d    192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   kube-system   calico-node-wlr5v                                       1/1     Running     0               11d    192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,481 [INFO]   kube-system   calico-node-xnzjw                                       1/1     Running     0               11d    192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   calico-node-xsltn                                       1/1     Running     0               11d    192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   coredns-668d6bf9bc-2f74f                                1/1     Running     0               2d6h   192.168.15.230    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   coredns-668d6bf9bc-qnzjq                                1/1     Running     0               14h    192.168.132.176   worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   etcd-master-m001                                        1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   kube-apiserver-master-m001                              1/1     Running     1 (3d2h ago)    11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   kube-controller-manager-master-m001                     1/1     Running     13 (117m ago)   11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   kube-proxy-5lzhj                                        1/1     Running     0               11d    192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   kube-proxy-7jqkv                                        1/1     Running     0               11d    192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   kube-proxy-cv5dt                                        1/1     Running     0               11d    192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   kube-proxy-fvpmr                                        1/1     Running     0               11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   kube-proxy-hgs5z                                        1/1     Running     0               11d    192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   kube-proxy-kmgqr                                        1/1     Running     0               11d    192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   kube-proxy-rdbz5                                        1/1     Running     0               11d    192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   kube-proxy-w8mnb                                        1/1     Running     0               11d    192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   kube-proxy-x9jxr                                        1/1     Running     0               11d    192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO]   kube-system   kube-scheduler-master-m001                              1/1     Running     12 (117m ago)   11d    192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,482 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: Pod distribution by node:[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,582 [INFO]   Node master-m003: 37 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,582 [INFO]   Node worker-w005: 13 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,582 [INFO]   Node 15h: 1 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,582 [INFO]   Node worker-w006: 3 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,582 [INFO]   Node worker-w002: 2 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,582 [INFO]   Node worker-w001: 3 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,582 [INFO]   Node master-m002: 2 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,583 [INFO]   Node master-m001: 3 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,583 [INFO]   Node worker-w003: 2 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,583 [INFO]   Node worker-w004: 2 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,583 [INFO]   Node 11d: 3 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,583 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: Filtering for simulation services:[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,773 [INFO] Node master-m001 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,774 [INFO] Node master-m002 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,774 [INFO] Node master-m003 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,774 [INFO] Node worker-w001 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,774 [INFO] Node worker-w002 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,774 [INFO] Node worker-w003 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,774 [INFO] Node worker-w004 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,774 [INFO] Node worker-w005 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,774 [INFO] Node worker-w006 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,779 [WARNING] No pods found for etcd-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,781 [WARNING] No pods found for postgres-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,783 [WARNING] No pods found for redis-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,785 [WARNING] No pods found for nginx-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,787 [WARNING] No pods found for auth-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,787 [INFO] Completed full health check[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,787 [INFO] Simulating node recovery for worker-w003 using Kubernetes API[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,802 [INFO] Removed simulated-failure taint from node worker-w003[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,815 [INFO] Node worker-w003 uncordoned and ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,816 [INFO] Node worker-w003 has been powered back on[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:53:23,816 [INFO] Waiting 60 seconds for the cluster to stabilize after recovery...[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,867 [INFO] Running final health check[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,867 [INFO] Starting full health check[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,867 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: ============ DETAILED NODE STATUS ============[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,867 [INFO] Basic Node Information (kubectl get nodes -o wide):[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,960 [INFO]   NAME          STATUS   ROLES           AGE   VERSION    INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,960 [INFO]   master-m001   Ready    control-plane   11d   v1.32.11   192.168.56.101   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,961 [INFO]   master-m002   Ready    control-plane   11d   v1.32.11   192.168.56.102   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,961 [INFO]   master-m003   Ready    control-plane   11d   v1.32.11   192.168.56.103   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,961 [INFO]   worker-w001   Ready    <none>          11d   v1.32.11   192.168.56.104   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,961 [INFO]   worker-w002   Ready    <none>          11d   v1.32.11   192.168.56.105   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,961 [INFO]   worker-w003   Ready    <none>          11d   v1.32.11   192.168.56.106   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,961 [INFO]   worker-w004   Ready    <none>          11d   v1.32.11   192.168.56.107   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,961 [INFO]   worker-w005   Ready    <none>          11d   v1.32.11   192.168.56.108   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,961 [INFO]   worker-w006   Ready    <none>          11d   v1.32.11   192.168.56.109   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,961 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: Enhanced Node Status (with taint and cordon indicators):[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:23,962 [INFO]   NAME                STATUS    ROLES           ZONE   CORDONED   TAINTS[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:24,310 [INFO]   master-m001     Ready  ‚úì worker         R1    No       node-role.kubernetes.io/control-plane [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:24,514 [INFO]   master-m002     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:24,688 [INFO]   master-m003     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:24,872 [INFO]   worker-w001     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,111 [INFO]   worker-w002     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,294 [INFO]   worker-w003     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,472 [INFO]   worker-w004     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,656 [INFO]   worker-w005     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,836 [INFO]   worker-w006     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,837 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: Legend:[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,837 [INFO]   ‚úì = Node is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,837 [INFO]   ‚ö†Ô∏è = Warning indicator (NotReady, Cordoned, or has simulated-failure taint)[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,837 [INFO] ============ DETAILED POD INFORMATION ============[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,837 [INFO] Running 'kubectl get pods -o wide' to show detailed pod placement:[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,956 [INFO]   NAMESPACE     NAME                                                    READY   STATUS      RESTARTS        AGE     IP                NODE          NOMINATED NODE   READINESS GATES[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          argo-server-5c69cb69db-gdkl6                            1/1     Running     0               8d      192.168.221.65    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-bench-ptngm-initialize-metrics-940927476     0/2     Completed   0               3d7h    192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-bench-ptngm-run-health-check-1168793163      0/2     Completed   0               3d7h    192.168.221.67    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-bench-ptngm-run-health-check-1185570782      0/2     Completed   0               3d7h    192.168.221.66    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-bench-ptngm-run-health-check-1202348401      0/2     Completed   0               3d7h    192.168.221.122   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-bench-wf87f-initialize-metrics-3677018408    0/2     Completed   0               3d9h    192.168.221.100   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-bench-wf87f-run-health-check-2914150102      0/2     Completed   0               3d9h    192.168.221.105   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-bench-wf87f-run-health-check-3931060015      0/2     Completed   0               3d9h    192.168.221.104   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-bench-wf87f-run-health-check-3947837634      0/2     Completed   0               3d9h    192.168.221.98    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-bench-wf87f-run-health-check-3964615253      0/2     Completed   0               3d9h    192.168.221.103   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-bench-wf87f-run-node-simulation-4173146970   0/2     Completed   0               3d9h    192.168.221.101   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-bench-wf87f-run-rack-simulation-1356070019   0/2     Completed   0               3d9h    192.168.221.109   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-heft-4cqbx-health-check-1589398418           0/2     Error       0               16h     192.168.15.231    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-heft-4cqbx-heft-initialize-2594215169        0/2     Completed   0               16h     192.168.221.79    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-heft-76kbp-health-check-270747540            0/2     Error       0               16h     192.168.15.237    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-heft-76kbp-heft-initialize-3574960751        0/2     Completed   0               16h     192.168.221.86    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-heft-b85xr-health-check-2840770649           0/2     Error       0               16h     192.168.15.240    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-heft-b85xr-heft-initialize-1754406316        0/2     Completed   0               16h     192.168.221.88    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-heft-fdw9f-health-check-1896357264           0/2     Error       0               16h     192.168.15.235    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-heft-fdw9f-heft-initialize-2651619139        0/2     Completed   0               16h     192.168.221.77    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-heft-gf256-health-check-980174358            0/2     Error       0               16h     192.168.15.236    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-heft-gf256-heft-initialize-1548293021        0/2     Completed   0               16h     192.168.221.84    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-heft-gxwpg-health-check-3445304423           0/2     Error       0               16h     192.168.15.233    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,957 [INFO]   argo          resilience-heft-gxwpg-heft-initialize-2377397022        0/2     Completed   0               16h     192.168.221.81    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-jx8fh-health-check-3032273300           0/2     Completed   0               2m58s   192.168.221.72    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-jx8fh-health-check-3049050919           0/2     Completed   0               2m58s   192.168.221.76    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-jx8fh-health-check-3065828538           0/2     Completed   0               2m58s   192.168.221.74    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-jx8fh-heft-initialize-4056367215        0/2     Completed   0               3m8s    192.168.221.73    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-jx8fh-node-failure-sim-2830132693       2/2     Running     0               2m26s   192.168.221.75    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-pc2kb-health-check-3258812212           0/2     Error       0               16h     192.168.15.238    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-pc2kb-heft-initialize-321333135         0/2     Completed   0               16h     192.168.221.83    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-qsmch-health-check-283908068            0/2     Error       0               16h     192.168.15.232    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-qsmch-heft-initialize-1908810015        0/2     Completed   0               16h     192.168.221.82    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-r2w8l-health-check-366927355            0/2     Error       0               16h     192.168.15.239    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-r2w8l-heft-initialize-3054048250        0/2     Completed   0               16h     192.168.221.85    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-t988k-health-check-612195296            0/2     Error       0               16h     192.168.15.234    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-t988k-heft-initialize-164752883         0/2     Completed   0               16h     192.168.221.80    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-vlt2m-health-check-2709447919           0/2     Error       0               15h     192.168.221.119   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-vlt2m-health-check-2726225538           0/2     Error       0               15h     192.168.221.120   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-vlt2m-health-check-2743003157           0/2     Error       0               15h     192.168.221.121   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-vlt2m-heft-initialize-840404112         0/2     Completed   0               15h     192.168.221.118   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-x86wd-health-check-2184182048           0/2     Error       0               15h     192.168.221.123   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-x86wd-health-check-2200959667           0/2     Error       0               15h     192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-x86wd-health-check-2234514905           0/2     Error       0               15h     192.168.221.124   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          resilience-heft-x86wd-heft-initialize-2152040770        0/2     Completed   0               15h     192.168.221.127   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   argo          workflow-controller-ccbd949dc-t4rx9                     1/1     Running     1 (119m ago)    15h     192.168.195.243   worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   kube-system   calico-kube-controllers-7498b9bb4c-xd7tb                1/1     Running     0               2d5h    192.168.191.108   worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   kube-system   calico-node-4zhd4                                       1/1     Running     0               11d     192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   kube-system   calico-node-75nx6                                       1/1     Running     0               11d     192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   kube-system   calico-node-7lkdq                                       1/1     Running     0               11d     192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,958 [INFO]   kube-system   calico-node-85f8c                                       1/1     Running     0               11d     192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   calico-node-j8nb9                                       1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   calico-node-lbcb2                                       1/1     Running     0               11d     192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   calico-node-wlr5v                                       1/1     Running     0               11d     192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   calico-node-xnzjw                                       1/1     Running     0               11d     192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   calico-node-xsltn                                       1/1     Running     0               11d     192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   coredns-668d6bf9bc-2f74f                                1/1     Running     0               2d7h    192.168.15.230    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   coredns-668d6bf9bc-qnzjq                                1/1     Running     0               15h     192.168.132.176   worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   etcd-master-m001                                        1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   kube-apiserver-master-m001                              1/1     Running     1 (3d2h ago)    11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   kube-controller-manager-master-m001                     1/1     Running     13 (118m ago)   11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   kube-proxy-5lzhj                                        1/1     Running     0               11d     192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   kube-proxy-7jqkv                                        1/1     Running     0               11d     192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   kube-proxy-cv5dt                                        1/1     Running     0               11d     192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   kube-proxy-fvpmr                                        1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   kube-proxy-hgs5z                                        1/1     Running     0               11d     192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   kube-proxy-kmgqr                                        1/1     Running     0               11d     192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   kube-proxy-rdbz5                                        1/1     Running     0               11d     192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   kube-proxy-w8mnb                                        1/1     Running     0               11d     192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   kube-proxy-x9jxr                                        1/1     Running     0               11d     192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO]   kube-system   kube-scheduler-master-m001                              1/1     Running     12 (118m ago)   11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:25,959 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: Pod distribution by node:[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,070 [INFO]   Node master-m003: 37 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,070 [INFO]   Node worker-w005: 13 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,070 [INFO]   Node 15h: 1 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,070 [INFO]   Node worker-w006: 3 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,070 [INFO]   Node worker-w002: 2 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,070 [INFO]   Node worker-w001: 3 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,071 [INFO]   Node master-m002: 2 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,071 [INFO]   Node master-m001: 3 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,071 [INFO]   Node worker-w003: 2 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,071 [INFO]   Node worker-w004: 2 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,071 [INFO]   Node 11d: 3 pods[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,071 [INFO] [0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: Filtering for simulation services:[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,195 [INFO] Node master-m001 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,195 [INFO] Node master-m002 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,195 [INFO] Node master-m003 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,195 [INFO] Node worker-w001 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,196 [INFO] Node worker-w002 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,196 [INFO] Node worker-w003 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,196 [INFO] Node worker-w004 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,196 [INFO] Node worker-w005 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,196 [INFO] Node worker-w006 is Ready[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,199 [WARNING] No pods found for etcd-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,201 [WARNING] No pods found for postgres-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,203 [WARNING] No pods found for redis-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,205 [WARNING] No pods found for nginx-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,208 [WARNING] No pods found for auth-sim[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: 2026-01-06 05:54:26,208 [INFO] Completed full health check[0m
[36mresilience-heft-jx8fh-node-failure-sim-2830132693: time="2026-01-06T05:54:27.362Z" level=info msg="sub-process exited" argo=true error="<nil>"[0m
[37mresilience-heft-jx8fh-health-check-354772983: Log directory created/verified: /app/logs[0m
[37mresilience-heft-jx8fh-health-check-354772983: File logging configured successfully[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,139 [INFO] Loaded in-cluster Kubernetes config[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,139 [INFO] Running on host: resilience-heft-jx8fh-health-check-354772983[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,139 [INFO] Detected current node: master-m003, zone: R3[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,139 [INFO] Checking if we have permissions to modify nodes...[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,160 [INFO] Testing permissions using node: master-m001[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,166 [INFO] Permission check successful - we can modify nodes[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,167 [INFO] Using real Kubernetes API for node control[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,167 [INFO] Action received: health-check[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,167 [INFO] Stabilization time: 10 seconds[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,167 [INFO] Starting full health check[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,167 [INFO] [0m
[37mresilience-heft-jx8fh-health-check-354772983: ============ DETAILED NODE STATUS ============[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,167 [INFO] Basic Node Information (kubectl get nodes -o wide):[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,225 [INFO]   NAME          STATUS   ROLES           AGE   VERSION    INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,225 [INFO]   master-m001   Ready    control-plane   11d   v1.32.11   192.168.56.101   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,225 [INFO]   master-m002   Ready    control-plane   11d   v1.32.11   192.168.56.102   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,225 [INFO]   master-m003   Ready    control-plane   11d   v1.32.11   192.168.56.103   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,225 [INFO]   worker-w001   Ready    <none>          11d   v1.32.11   192.168.56.104   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,225 [INFO]   worker-w002   Ready    <none>          11d   v1.32.11   192.168.56.105   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,225 [INFO]   worker-w003   Ready    <none>          11d   v1.32.11   192.168.56.106   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,225 [INFO]   worker-w004   Ready    <none>          11d   v1.32.11   192.168.56.107   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,225 [INFO]   worker-w005   Ready    <none>          11d   v1.32.11   192.168.56.108   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,225 [INFO]   worker-w006   Ready    <none>          11d   v1.32.11   192.168.56.109   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,225 [INFO] [0m
[37mresilience-heft-jx8fh-health-check-354772983: Enhanced Node Status (with taint and cordon indicators):[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,225 [INFO]   NAME                STATUS    ROLES           ZONE   CORDONED   TAINTS[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,451 [INFO]   master-m001     Ready  ‚úì worker         R1    No       node-role.kubernetes.io/control-plane [0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,648 [INFO]   master-m002     Ready  ‚úì worker         R2    No       None [0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:46,843 [INFO]   master-m003     Ready  ‚úì worker         R3    No       None [0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,006 [INFO]   worker-w001     Ready  ‚úì worker         R1    No       None [0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,162 [INFO]   worker-w002     Ready  ‚úì worker         R1    No       None [0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,358 [INFO]   worker-w003     Ready  ‚úì worker         R2    No       None [0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,544 [INFO]   worker-w004     Ready  ‚úì worker         R2    No       None [0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,720 [INFO]   worker-w005     Ready  ‚úì worker         R3    No       None [0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,866 [INFO]   worker-w006     Ready  ‚úì worker         R3    No       None [0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,866 [INFO] [0m
[37mresilience-heft-jx8fh-health-check-354772983: Legend:[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,867 [INFO]   ‚úì = Node is Ready[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,867 [INFO]   ‚ö†Ô∏è = Warning indicator (NotReady, Cordoned, or has simulated-failure taint)[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,867 [INFO] ============ DETAILED POD INFORMATION ============[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,867 [INFO] Running 'kubectl get pods -o wide' to show detailed pod placement:[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,946 [INFO]   NAMESPACE     NAME                                                    READY   STATUS      RESTARTS        AGE     IP                NODE          NOMINATED NODE   READINESS GATES[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          argo-server-5c69cb69db-gdkl6                            1/1     Running     0               8d      192.168.221.65    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-bench-ptngm-initialize-metrics-940927476     0/2     Completed   0               3d7h    192.168.221.125   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-bench-ptngm-run-health-check-1168793163      0/2     Completed   0               3d7h    192.168.221.67    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-bench-ptngm-run-health-check-1185570782      0/2     Completed   0               3d7h    192.168.221.66    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-bench-ptngm-run-health-check-1202348401      0/2     Completed   0               3d7h    192.168.221.122   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-bench-wf87f-initialize-metrics-3677018408    0/2     Completed   0               3d9h    192.168.221.100   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-bench-wf87f-run-health-check-2914150102      0/2     Completed   0               3d9h    192.168.221.105   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-bench-wf87f-run-health-check-3931060015      0/2     Completed   0               3d9h    192.168.221.104   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-bench-wf87f-run-health-check-3947837634      0/2     Completed   0               3d9h    192.168.221.98    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-bench-wf87f-run-health-check-3964615253      0/2     Completed   0               3d9h    192.168.221.103   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-bench-wf87f-run-node-simulation-4173146970   0/2     Completed   0               3d9h    192.168.221.101   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-bench-wf87f-run-rack-simulation-1356070019   0/2     Completed   0               3d9h    192.168.221.109   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-heft-4cqbx-health-check-1589398418           0/2     Error       0               16h     192.168.15.231    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-heft-4cqbx-heft-initialize-2594215169        0/2     Completed   0               16h     192.168.221.79    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-heft-76kbp-health-check-270747540            0/2     Error       0               16h     192.168.15.237    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,947 [INFO]   argo          resilience-heft-76kbp-heft-initialize-3574960751        0/2     Completed   0               16h     192.168.221.86    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-b85xr-health-check-2840770649           0/2     Error       0               16h     192.168.15.240    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-b85xr-heft-initialize-1754406316        0/2     Completed   0               16h     192.168.221.88    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-fdw9f-health-check-1896357264           0/2     Error       0               16h     192.168.15.235    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-fdw9f-heft-initialize-2651619139        0/2     Completed   0               16h     192.168.221.77    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-gf256-health-check-980174358            0/2     Error       0               16h     192.168.15.236    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-gf256-heft-initialize-1548293021        0/2     Completed   0               16h     192.168.221.84    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-gxwpg-health-check-3445304423           0/2     Error       0               16h     192.168.15.233    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-gxwpg-heft-initialize-2377397022        0/2     Completed   0               16h     192.168.221.81    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-jx8fh-health-check-3032273300           0/2     Completed   0               3m20s   192.168.221.72    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-jx8fh-health-check-3049050919           0/2     Completed   0               3m20s   192.168.221.76    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-jx8fh-health-check-3065828538           0/2     Completed   0               3m20s   192.168.221.74    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-jx8fh-health-check-354772983            2/2     Running     0               9s      192.168.221.78    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-jx8fh-heft-initialize-4056367215        0/2     Completed   0               3m30s   192.168.221.73    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-jx8fh-node-failure-sim-2830132693       0/2     Completed   0               2m48s   192.168.221.75    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-pc2kb-health-check-3258812212           0/2     Error       0               16h     192.168.15.238    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-pc2kb-heft-initialize-321333135         0/2     Completed   0               16h     192.168.221.83    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-qsmch-health-check-283908068            0/2     Error       0               16h     192.168.15.232    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-qsmch-heft-initialize-1908810015        0/2     Completed   0               16h     192.168.221.82    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-r2w8l-health-check-366927355            0/2     Error       0               16h     192.168.15.239    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-r2w8l-heft-initialize-3054048250        0/2     Completed   0               16h     192.168.221.85    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-t988k-health-check-612195296            0/2     Error       0               16h     192.168.15.234    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-t988k-heft-initialize-164752883         0/2     Completed   0               16h     192.168.221.80    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-vlt2m-health-check-2709447919           0/2     Error       0               15h     192.168.221.119   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-vlt2m-health-check-2726225538           0/2     Error       0               15h     192.168.221.120   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-vlt2m-health-check-2743003157           0/2     Error       0               15h     192.168.221.121   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-vlt2m-heft-initialize-840404112         0/2     Completed   0               15h     192.168.221.118   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-x86wd-health-check-2184182048           0/2     Error       0               15h     192.168.221.123   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-x86wd-health-check-2200959667           0/2     Error       0               15h     192.168.221.125   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-x86wd-health-check-2234514905           0/2     Error       0               15h     192.168.221.124   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          resilience-heft-x86wd-heft-initialize-2152040770        0/2     Completed   0               15h     192.168.221.127   master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   argo          workflow-controller-ccbd949dc-t4rx9                     1/1     Running     1 (119m ago)    15h     192.168.195.243   worker-w002   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   kube-system   calico-kube-controllers-7498b9bb4c-xd7tb                1/1     Running     0               2d5h    192.168.191.108   worker-w006   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   kube-system   calico-node-4zhd4                                       1/1     Running     0               11d     192.168.56.105    worker-w002   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   kube-system   calico-node-75nx6                                       1/1     Running     0               11d     192.168.56.109    worker-w006   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   kube-system   calico-node-7lkdq                                       1/1     Running     0               11d     192.168.56.104    worker-w001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   kube-system   calico-node-85f8c                                       1/1     Running     0               11d     192.168.56.102    master-m002   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   kube-system   calico-node-j8nb9                                       1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,948 [INFO]   kube-system   calico-node-lbcb2                                       1/1     Running     0               11d     192.168.56.106    worker-w003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   calico-node-wlr5v                                       1/1     Running     0               11d     192.168.56.107    worker-w004   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   calico-node-xnzjw                                       1/1     Running     0               11d     192.168.56.103    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   calico-node-xsltn                                       1/1     Running     0               11d     192.168.56.108    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   coredns-668d6bf9bc-2f74f                                1/1     Running     0               2d7h    192.168.15.230    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   coredns-668d6bf9bc-qnzjq                                1/1     Running     0               15h     192.168.132.176   worker-w001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   etcd-master-m001                                        1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   kube-apiserver-master-m001                              1/1     Running     1 (3d2h ago)    11d     192.168.56.101    master-m001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   kube-controller-manager-master-m001                     1/1     Running     13 (118m ago)   11d     192.168.56.101    master-m001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   kube-proxy-5lzhj                                        1/1     Running     0               11d     192.168.56.102    master-m002   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   kube-proxy-7jqkv                                        1/1     Running     0               11d     192.168.56.109    worker-w006   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   kube-proxy-cv5dt                                        1/1     Running     0               11d     192.168.56.108    worker-w005   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   kube-proxy-fvpmr                                        1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   kube-proxy-hgs5z                                        1/1     Running     0               11d     192.168.56.106    worker-w003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   kube-proxy-kmgqr                                        1/1     Running     0               11d     192.168.56.105    worker-w002   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   kube-proxy-rdbz5                                        1/1     Running     0               11d     192.168.56.107    worker-w004   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   kube-proxy-w8mnb                                        1/1     Running     0               11d     192.168.56.103    master-m003   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   kube-proxy-x9jxr                                        1/1     Running     0               11d     192.168.56.104    worker-w001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO]   kube-system   kube-scheduler-master-m001                              1/1     Running     12 (118m ago)   11d     192.168.56.101    master-m001   <none>           <none>[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:47,949 [INFO] [0m
[37mresilience-heft-jx8fh-health-check-354772983: Pod distribution by node:[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,034 [INFO]   Node master-m003: 38 pods[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,035 [INFO]   Node worker-w005: 13 pods[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,035 [INFO]   Node 15h: 1 pods[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,035 [INFO]   Node worker-w006: 3 pods[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,035 [INFO]   Node worker-w002: 2 pods[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,035 [INFO]   Node worker-w001: 3 pods[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,035 [INFO]   Node master-m002: 2 pods[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,035 [INFO]   Node master-m001: 3 pods[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,035 [INFO]   Node worker-w003: 2 pods[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,035 [INFO]   Node worker-w004: 2 pods[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,035 [INFO]   Node 11d: 3 pods[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,036 [INFO] [0m
[37mresilience-heft-jx8fh-health-check-354772983: Filtering for simulation services:[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,134 [INFO] Node master-m001 is Ready[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,134 [INFO] Node master-m002 is Ready[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,134 [INFO] Node master-m003 is Ready[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,134 [INFO] Node worker-w001 is Ready[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,134 [INFO] Node worker-w002 is Ready[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,135 [INFO] Node worker-w003 is Ready[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,135 [INFO] Node worker-w004 is Ready[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,135 [INFO] Node worker-w005 is Ready[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,135 [INFO] Node worker-w006 is Ready[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,137 [WARNING] No pods found for etcd-sim[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,139 [WARNING] No pods found for postgres-sim[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,141 [WARNING] No pods found for redis-sim[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,142 [WARNING] No pods found for nginx-sim[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,144 [WARNING] No pods found for auth-sim[0m
[37mresilience-heft-jx8fh-health-check-354772983: 2026-01-06 05:54:48,144 [INFO] Completed full health check[0m
[37mresilience-heft-jx8fh-health-check-354772983: time="2026-01-06T05:54:48.900Z" level=info msg="sub-process exited" argo=true error="<nil>"[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: Log directory created/verified: /app/logs[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: File logging configured successfully[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,221 [INFO] Loaded in-cluster Kubernetes config[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,222 [INFO] Running on host: resilience-heft-jx8fh-rack-failure-sim-447709032[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,222 [INFO] Detected current node: master-m003, zone: R3[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,222 [INFO] Checking if we have permissions to modify nodes...[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,256 [INFO] Testing permissions using node: master-m001[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,264 [INFO] Permission check successful - we can modify nodes[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,265 [INFO] Using real Kubernetes API for node control[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,266 [INFO] Action received: simulate-rack[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,266 [INFO] Stabilization time: 60 seconds[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,266 [INFO] Current node: master-m003 in zone: R3[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,266 [INFO] Safe zones for rack simulation: ['R1', 'R2'][0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,266 [INFO] Simulating full rack (zone) failure: R2 with nodes: ['master-m002', 'worker-w003', 'worker-w004'][0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,267 [INFO] Simulating node failure for master-m002 using Kubernetes API[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,288 [INFO] Node master-m002 cordoned[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,299 [INFO] Node master-m002 tainted with NoExecute[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,299 [INFO] Node master-m002 powered off (delay 5s)[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:04,299 [INFO] Node master-m002 powered off (delay 5s)[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:09,323 [INFO] Simulating node failure for worker-w003 using Kubernetes API[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:09,348 [INFO] Node worker-w003 cordoned[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:09,372 [INFO] Node worker-w003 tainted with NoExecute[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:09,372 [INFO] Node worker-w003 powered off (delay 5s)[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:09,373 [INFO] Node worker-w003 powered off (delay 5s)[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:14,377 [INFO] Simulating node failure for worker-w004 using Kubernetes API[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:14,397 [INFO] Node worker-w004 cordoned[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:14,408 [INFO] Node worker-w004 tainted with NoExecute[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:14,408 [INFO] Node worker-w004 powered off (delay 5s)[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:14,408 [INFO] Node worker-w004 powered off (delay 5s)[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:55:19,410 [INFO] Waiting 60 seconds for the cluster to stabilize before health check...[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,439 [INFO] Running health check after rack power off[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,440 [INFO] Starting full health check[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,440 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: ============ DETAILED NODE STATUS ============[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,440 [INFO] Basic Node Information (kubectl get nodes -o wide):[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,508 [INFO]   NAME          STATUS                     ROLES           AGE   VERSION    INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,508 [INFO]   master-m001   Ready                      control-plane   11d   v1.32.11   192.168.56.101   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,509 [INFO]   master-m002   Ready,SchedulingDisabled   control-plane   11d   v1.32.11   192.168.56.102   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,509 [INFO]   master-m003   Ready                      control-plane   11d   v1.32.11   192.168.56.103   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,509 [INFO]   worker-w001   Ready                      <none>          11d   v1.32.11   192.168.56.104   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,509 [INFO]   worker-w002   Ready                      <none>          11d   v1.32.11   192.168.56.105   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,509 [INFO]   worker-w003   Ready,SchedulingDisabled   <none>          11d   v1.32.11   192.168.56.106   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,509 [INFO]   worker-w004   Ready,SchedulingDisabled   <none>          11d   v1.32.11   192.168.56.107   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,509 [INFO]   worker-w005   Ready                      <none>          11d   v1.32.11   192.168.56.108   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,509 [INFO]   worker-w006   Ready                      <none>          11d   v1.32.11   192.168.56.109   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,509 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: Enhanced Node Status (with taint and cordon indicators):[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,509 [INFO]   NAME                STATUS    ROLES           ZONE   CORDONED   TAINTS[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,770 [INFO]   master-m001     Ready  ‚úì worker         R1    No       node-role.kubernetes.io/control-plane [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:19,952 [INFO]   master-m002     Ready  ‚úì worker         R2    YES     ‚ö†Ô∏è simulated-failure, node.kubernetes.io/unschedulable ‚ö†Ô∏è[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:20,129 [INFO]   master-m003     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:20,305 [INFO]   worker-w001     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:20,485 [INFO]   worker-w002     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:20,672 [INFO]   worker-w003     Ready  ‚úì worker         R2    YES     ‚ö†Ô∏è simulated-failure, node.kubernetes.io/unschedulable ‚ö†Ô∏è[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:20,814 [INFO]   worker-w004     Ready  ‚úì worker         R2    YES     ‚ö†Ô∏è simulated-failure, node.kubernetes.io/unschedulable ‚ö†Ô∏è[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:20,970 [INFO]   worker-w005     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,112 [INFO]   worker-w006     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,113 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: Legend:[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,113 [INFO]   ‚úì = Node is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,113 [INFO]   ‚ö†Ô∏è = Warning indicator (NotReady, Cordoned, or has simulated-failure taint)[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,113 [INFO] ============ DETAILED POD INFORMATION ============[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,113 [INFO] Running 'kubectl get pods -o wide' to show detailed pod placement:[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,199 [INFO]   NAMESPACE     NAME                                                    READY   STATUS      RESTARTS        AGE     IP                NODE          NOMINATED NODE   READINESS GATES[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          argo-server-5c69cb69db-gdkl6                            1/1     Running     0               8d      192.168.221.65    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-bench-ptngm-initialize-metrics-940927476     0/2     Completed   0               3d7h    192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-bench-ptngm-run-health-check-1168793163      0/2     Completed   0               3d7h    192.168.221.67    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-bench-ptngm-run-health-check-1185570782      0/2     Completed   0               3d7h    192.168.221.66    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-bench-ptngm-run-health-check-1202348401      0/2     Completed   0               3d7h    192.168.221.122   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-bench-wf87f-initialize-metrics-3677018408    0/2     Completed   0               3d9h    192.168.221.100   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-bench-wf87f-run-health-check-2914150102      0/2     Completed   0               3d9h    192.168.221.105   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-bench-wf87f-run-health-check-3931060015      0/2     Completed   0               3d9h    192.168.221.104   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-bench-wf87f-run-health-check-3947837634      0/2     Completed   0               3d9h    192.168.221.98    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-bench-wf87f-run-health-check-3964615253      0/2     Completed   0               3d9h    192.168.221.103   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-bench-wf87f-run-node-simulation-4173146970   0/2     Completed   0               3d9h    192.168.221.101   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-bench-wf87f-run-rack-simulation-1356070019   0/2     Completed   0               3d9h    192.168.221.109   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-heft-4cqbx-health-check-1589398418           0/2     Error       0               16h     192.168.15.231    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-heft-4cqbx-heft-initialize-2594215169        0/2     Completed   0               16h     192.168.221.79    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-heft-76kbp-health-check-270747540            0/2     Error       0               16h     192.168.15.237    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-heft-76kbp-heft-initialize-3574960751        0/2     Completed   0               16h     192.168.221.86    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-heft-b85xr-health-check-2840770649           0/2     Error       0               16h     192.168.15.240    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-heft-b85xr-heft-initialize-1754406316        0/2     Completed   0               16h     192.168.221.88    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,200 [INFO]   argo          resilience-heft-fdw9f-health-check-1896357264           0/2     Error       0               16h     192.168.15.235    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-fdw9f-heft-initialize-2651619139        0/2     Completed   0               16h     192.168.221.77    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-gf256-health-check-980174358            0/2     Error       0               16h     192.168.15.236    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-gf256-heft-initialize-1548293021        0/2     Completed   0               16h     192.168.221.84    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-gxwpg-health-check-3445304423           0/2     Error       0               16h     192.168.15.233    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-gxwpg-heft-initialize-2377397022        0/2     Completed   0               16h     192.168.221.81    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-jx8fh-health-check-3032273300           0/2     Completed   0               4m54s   192.168.221.72    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-jx8fh-health-check-3049050919           0/2     Completed   0               4m54s   192.168.221.76    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-jx8fh-health-check-3065828538           0/2     Completed   0               4m54s   192.168.221.74    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-jx8fh-health-check-354772983            0/2     Completed   0               103s    192.168.221.78    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-jx8fh-heft-initialize-4056367215        0/2     Completed   0               5m4s    192.168.221.73    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-jx8fh-node-failure-sim-2830132693       0/2     Completed   0               4m22s   192.168.221.75    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-jx8fh-rack-failure-sim-447709032        2/2     Running     0               83s     192.168.221.79    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-pc2kb-health-check-3258812212           0/2     Error       0               16h     192.168.15.238    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-pc2kb-heft-initialize-321333135         0/2     Completed   0               16h     192.168.221.83    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-qsmch-health-check-283908068            0/2     Error       0               16h     192.168.15.232    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-qsmch-heft-initialize-1908810015        0/2     Completed   0               16h     192.168.221.82    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-r2w8l-health-check-366927355            0/2     Error       0               16h     192.168.15.239    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-r2w8l-heft-initialize-3054048250        0/2     Completed   0               16h     192.168.221.85    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-t988k-health-check-612195296            0/2     Error       0               16h     192.168.15.234    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-t988k-heft-initialize-164752883         0/2     Completed   0               16h     192.168.221.80    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-vlt2m-health-check-2709447919           0/2     Error       0               15h     192.168.221.119   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-vlt2m-health-check-2726225538           0/2     Error       0               15h     192.168.221.120   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-vlt2m-health-check-2743003157           0/2     Error       0               15h     192.168.221.121   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-vlt2m-heft-initialize-840404112         0/2     Completed   0               15h     192.168.221.118   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-x86wd-health-check-2184182048           0/2     Error       0               15h     192.168.221.123   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-x86wd-health-check-2200959667           0/2     Error       0               15h     192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-x86wd-health-check-2234514905           0/2     Error       0               15h     192.168.221.124   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          resilience-heft-x86wd-heft-initialize-2152040770        0/2     Completed   0               15h     192.168.221.127   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   argo          workflow-controller-ccbd949dc-t4rx9                     1/1     Running     1 (120m ago)    15h     192.168.195.243   worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   kube-system   calico-kube-controllers-7498b9bb4c-xd7tb                1/1     Running     0               2d5h    192.168.191.108   worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   kube-system   calico-node-4zhd4                                       1/1     Running     0               11d     192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,201 [INFO]   kube-system   calico-node-75nx6                                       1/1     Running     0               11d     192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   calico-node-7lkdq                                       1/1     Running     0               11d     192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   calico-node-85f8c                                       1/1     Running     0               11d     192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   calico-node-j8nb9                                       1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   calico-node-lbcb2                                       1/1     Running     0               11d     192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   calico-node-wlr5v                                       1/1     Running     0               11d     192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   calico-node-xnzjw                                       1/1     Running     0               11d     192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   calico-node-xsltn                                       1/1     Running     0               11d     192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   coredns-668d6bf9bc-2f74f                                1/1     Running     0               2d7h    192.168.15.230    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   coredns-668d6bf9bc-qnzjq                                1/1     Running     0               15h     192.168.132.176   worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   etcd-master-m001                                        1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   kube-apiserver-master-m001                              1/1     Running     1 (3d2h ago)    11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   kube-controller-manager-master-m001                     1/1     Running     13 (120m ago)   11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   kube-proxy-5lzhj                                        1/1     Running     0               11d     192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   kube-proxy-7jqkv                                        1/1     Running     0               11d     192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   kube-proxy-cv5dt                                        1/1     Running     0               11d     192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   kube-proxy-fvpmr                                        1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   kube-proxy-hgs5z                                        1/1     Running     0               11d     192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   kube-proxy-kmgqr                                        1/1     Running     0               11d     192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   kube-proxy-rdbz5                                        1/1     Running     0               11d     192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   kube-proxy-w8mnb                                        1/1     Running     0               11d     192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   kube-proxy-x9jxr                                        1/1     Running     0               11d     192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO]   kube-system   kube-scheduler-master-m001                              1/1     Running     12 (120m ago)   11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,202 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: Pod distribution by node:[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,314 [INFO]   Node master-m003: 39 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,314 [INFO]   Node worker-w005: 13 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,314 [INFO]   Node 15h: 1 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,314 [INFO]   Node worker-w006: 3 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,314 [INFO]   Node worker-w002: 2 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,314 [INFO]   Node worker-w001: 3 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,314 [INFO]   Node master-m002: 2 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,314 [INFO]   Node master-m001: 3 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,314 [INFO]   Node worker-w003: 2 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,314 [INFO]   Node worker-w004: 2 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,314 [INFO]   Node 11d: 3 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,314 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: Filtering for simulation services:[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,440 [INFO] Node master-m001 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,440 [INFO] Node master-m002 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,440 [INFO] Node master-m003 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,440 [INFO] Node worker-w001 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,441 [INFO] Node worker-w002 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,441 [INFO] Node worker-w003 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,441 [INFO] Node worker-w004 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,441 [INFO] Node worker-w005 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,441 [INFO] Node worker-w006 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,444 [WARNING] No pods found for etcd-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,446 [WARNING] No pods found for postgres-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,448 [WARNING] No pods found for redis-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,450 [WARNING] No pods found for nginx-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,453 [WARNING] No pods found for auth-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,453 [INFO] Completed full health check[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:21,454 [INFO] Zone R2 remains down for 10 seconds[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,461 [INFO] Running health check before rack power on[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,461 [INFO] Starting full health check[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,461 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: ============ DETAILED NODE STATUS ============[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,461 [INFO] Basic Node Information (kubectl get nodes -o wide):[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,529 [INFO]   NAME          STATUS                     ROLES           AGE   VERSION    INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,529 [INFO]   master-m001   Ready                      control-plane   11d   v1.32.11   192.168.56.101   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,529 [INFO]   master-m002   Ready,SchedulingDisabled   control-plane   11d   v1.32.11   192.168.56.102   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,530 [INFO]   master-m003   Ready                      control-plane   11d   v1.32.11   192.168.56.103   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,530 [INFO]   worker-w001   Ready                      <none>          11d   v1.32.11   192.168.56.104   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,530 [INFO]   worker-w002   Ready                      <none>          11d   v1.32.11   192.168.56.105   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,530 [INFO]   worker-w003   Ready,SchedulingDisabled   <none>          11d   v1.32.11   192.168.56.106   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,530 [INFO]   worker-w004   Ready,SchedulingDisabled   <none>          11d   v1.32.11   192.168.56.107   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,530 [INFO]   worker-w005   Ready                      <none>          11d   v1.32.11   192.168.56.108   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,531 [INFO]   worker-w006   Ready                      <none>          11d   v1.32.11   192.168.56.109   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,531 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: Enhanced Node Status (with taint and cordon indicators):[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,531 [INFO]   NAME                STATUS    ROLES           ZONE   CORDONED   TAINTS[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:31,852 [INFO]   master-m001     Ready  ‚úì worker         R1    No       node-role.kubernetes.io/control-plane [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:32,034 [INFO]   master-m002     Ready  ‚úì worker         R2    YES     ‚ö†Ô∏è simulated-failure, node.kubernetes.io/unschedulable ‚ö†Ô∏è[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:32,214 [INFO]   master-m003     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:32,415 [INFO]   worker-w001     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:32,595 [INFO]   worker-w002     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:32,789 [INFO]   worker-w003     Ready  ‚úì worker         R2    YES     ‚ö†Ô∏è simulated-failure, node.kubernetes.io/unschedulable ‚ö†Ô∏è[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:32,948 [INFO]   worker-w004     Ready  ‚úì worker         R2    YES     ‚ö†Ô∏è simulated-failure, node.kubernetes.io/unschedulable ‚ö†Ô∏è[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,068 [INFO]   worker-w005     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,276 [INFO]   worker-w006     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,276 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: Legend:[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,277 [INFO]   ‚úì = Node is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,277 [INFO]   ‚ö†Ô∏è = Warning indicator (NotReady, Cordoned, or has simulated-failure taint)[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,277 [INFO] ============ DETAILED POD INFORMATION ============[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,277 [INFO] Running 'kubectl get pods -o wide' to show detailed pod placement:[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   NAMESPACE     NAME                                                    READY   STATUS      RESTARTS        AGE     IP                NODE          NOMINATED NODE   READINESS GATES[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   argo          argo-server-5c69cb69db-gdkl6                            1/1     Running     0               8d      192.168.221.65    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   argo          resilience-bench-ptngm-initialize-metrics-940927476     0/2     Completed   0               3d7h    192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   argo          resilience-bench-ptngm-run-health-check-1168793163      0/2     Completed   0               3d7h    192.168.221.67    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   argo          resilience-bench-ptngm-run-health-check-1185570782      0/2     Completed   0               3d7h    192.168.221.66    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   argo          resilience-bench-ptngm-run-health-check-1202348401      0/2     Completed   0               3d7h    192.168.221.122   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   argo          resilience-bench-wf87f-initialize-metrics-3677018408    0/2     Completed   0               3d9h    192.168.221.100   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   argo          resilience-bench-wf87f-run-health-check-2914150102      0/2     Completed   0               3d9h    192.168.221.105   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   argo          resilience-bench-wf87f-run-health-check-3931060015      0/2     Completed   0               3d9h    192.168.221.104   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   argo          resilience-bench-wf87f-run-health-check-3947837634      0/2     Completed   0               3d9h    192.168.221.98    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   argo          resilience-bench-wf87f-run-health-check-3964615253      0/2     Completed   0               3d9h    192.168.221.103   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   argo          resilience-bench-wf87f-run-node-simulation-4173146970   0/2     Completed   0               3d9h    192.168.221.101   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   argo          resilience-bench-wf87f-run-rack-simulation-1356070019   0/2     Completed   0               3d9h    192.168.221.109   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,401 [INFO]   argo          resilience-heft-4cqbx-health-check-1589398418           0/2     Error       0               16h     192.168.15.231    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,402 [INFO]   argo          resilience-heft-4cqbx-heft-initialize-2594215169        0/2     Completed   0               16h     192.168.221.79    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,402 [INFO]   argo          resilience-heft-76kbp-health-check-270747540            0/2     Error       0               16h     192.168.15.237    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,402 [INFO]   argo          resilience-heft-76kbp-heft-initialize-3574960751        0/2     Completed   0               16h     192.168.221.86    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,402 [INFO]   argo          resilience-heft-b85xr-health-check-2840770649           0/2     Error       0               16h     192.168.15.240    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,402 [INFO]   argo          resilience-heft-b85xr-heft-initialize-1754406316        0/2     Completed   0               16h     192.168.221.88    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,402 [INFO]   argo          resilience-heft-fdw9f-health-check-1896357264           0/2     Error       0               16h     192.168.15.235    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,402 [INFO]   argo          resilience-heft-fdw9f-heft-initialize-2651619139        0/2     Completed   0               16h     192.168.221.77    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,403 [INFO]   argo          resilience-heft-gf256-health-check-980174358            0/2     Error       0               16h     192.168.15.236    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,403 [INFO]   argo          resilience-heft-gf256-heft-initialize-1548293021        0/2     Completed   0               16h     192.168.221.84    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,403 [INFO]   argo          resilience-heft-gxwpg-health-check-3445304423           0/2     Error       0               16h     192.168.15.233    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,403 [INFO]   argo          resilience-heft-gxwpg-heft-initialize-2377397022        0/2     Completed   0               16h     192.168.221.81    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,403 [INFO]   argo          resilience-heft-jx8fh-health-check-3032273300           0/2     Completed   0               5m6s    192.168.221.72    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,403 [INFO]   argo          resilience-heft-jx8fh-health-check-3049050919           0/2     Completed   0               5m6s    192.168.221.76    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,403 [INFO]   argo          resilience-heft-jx8fh-health-check-3065828538           0/2     Completed   0               5m6s    192.168.221.74    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,404 [INFO]   argo          resilience-heft-jx8fh-health-check-354772983            0/2     Completed   0               115s    192.168.221.78    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,404 [INFO]   argo          resilience-heft-jx8fh-heft-initialize-4056367215        0/2     Completed   0               5m16s   192.168.221.73    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,404 [INFO]   argo          resilience-heft-jx8fh-node-failure-sim-2830132693       0/2     Completed   0               4m34s   192.168.221.75    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,404 [INFO]   argo          resilience-heft-jx8fh-rack-failure-sim-447709032        2/2     Running     0               95s     192.168.221.79    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,404 [INFO]   argo          resilience-heft-pc2kb-health-check-3258812212           0/2     Error       0               16h     192.168.15.238    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,404 [INFO]   argo          resilience-heft-pc2kb-heft-initialize-321333135         0/2     Completed   0               16h     192.168.221.83    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,404 [INFO]   argo          resilience-heft-qsmch-health-check-283908068            0/2     Error       0               16h     192.168.15.232    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,404 [INFO]   argo          resilience-heft-qsmch-heft-initialize-1908810015        0/2     Completed   0               16h     192.168.221.82    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,405 [INFO]   argo          resilience-heft-r2w8l-health-check-366927355            0/2     Error       0               16h     192.168.15.239    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,405 [INFO]   argo          resilience-heft-r2w8l-heft-initialize-3054048250        0/2     Completed   0               16h     192.168.221.85    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,405 [INFO]   argo          resilience-heft-t988k-health-check-612195296            0/2     Error       0               16h     192.168.15.234    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,405 [INFO]   argo          resilience-heft-t988k-heft-initialize-164752883         0/2     Completed   0               16h     192.168.221.80    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,405 [INFO]   argo          resilience-heft-vlt2m-health-check-2709447919           0/2     Error       0               15h     192.168.221.119   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,405 [INFO]   argo          resilience-heft-vlt2m-health-check-2726225538           0/2     Error       0               15h     192.168.221.120   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,405 [INFO]   argo          resilience-heft-vlt2m-health-check-2743003157           0/2     Error       0               15h     192.168.221.121   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,405 [INFO]   argo          resilience-heft-vlt2m-heft-initialize-840404112         0/2     Completed   0               15h     192.168.221.118   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,406 [INFO]   argo          resilience-heft-x86wd-health-check-2184182048           0/2     Error       0               15h     192.168.221.123   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,406 [INFO]   argo          resilience-heft-x86wd-health-check-2200959667           0/2     Error       0               15h     192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,406 [INFO]   argo          resilience-heft-x86wd-health-check-2234514905           0/2     Error       0               15h     192.168.221.124   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,406 [INFO]   argo          resilience-heft-x86wd-heft-initialize-2152040770        0/2     Completed   0               15h     192.168.221.127   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,406 [INFO]   argo          workflow-controller-ccbd949dc-t4rx9                     1/1     Running     1 (121m ago)    15h     192.168.195.243   worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,406 [INFO]   kube-system   calico-kube-controllers-7498b9bb4c-xd7tb                1/1     Running     0               2d5h    192.168.191.108   worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,406 [INFO]   kube-system   calico-node-4zhd4                                       1/1     Running     0               11d     192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,407 [INFO]   kube-system   calico-node-75nx6                                       1/1     Running     0               11d     192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,407 [INFO]   kube-system   calico-node-7lkdq                                       1/1     Running     0               11d     192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,407 [INFO]   kube-system   calico-node-85f8c                                       1/1     Running     0               11d     192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,407 [INFO]   kube-system   calico-node-j8nb9                                       1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,407 [INFO]   kube-system   calico-node-lbcb2                                       1/1     Running     0               11d     192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,407 [INFO]   kube-system   calico-node-wlr5v                                       1/1     Running     0               11d     192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,407 [INFO]   kube-system   calico-node-xnzjw                                       1/1     Running     0               11d     192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,407 [INFO]   kube-system   calico-node-xsltn                                       1/1     Running     0               11d     192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,408 [INFO]   kube-system   coredns-668d6bf9bc-2f74f                                1/1     Running     0               2d7h    192.168.15.230    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,408 [INFO]   kube-system   coredns-668d6bf9bc-qnzjq                                1/1     Running     0               15h     192.168.132.176   worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,408 [INFO]   kube-system   etcd-master-m001                                        1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,408 [INFO]   kube-system   kube-apiserver-master-m001                              1/1     Running     1 (3d2h ago)    11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,408 [INFO]   kube-system   kube-controller-manager-master-m001                     1/1     Running     13 (120m ago)   11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,408 [INFO]   kube-system   kube-proxy-5lzhj                                        1/1     Running     0               11d     192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,408 [INFO]   kube-system   kube-proxy-7jqkv                                        1/1     Running     0               11d     192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,408 [INFO]   kube-system   kube-proxy-cv5dt                                        1/1     Running     0               11d     192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,409 [INFO]   kube-system   kube-proxy-fvpmr                                        1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,409 [INFO]   kube-system   kube-proxy-hgs5z                                        1/1     Running     0               11d     192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,409 [INFO]   kube-system   kube-proxy-kmgqr                                        1/1     Running     0               11d     192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,409 [INFO]   kube-system   kube-proxy-rdbz5                                        1/1     Running     0               11d     192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,409 [INFO]   kube-system   kube-proxy-w8mnb                                        1/1     Running     0               11d     192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,409 [INFO]   kube-system   kube-proxy-x9jxr                                        1/1     Running     0               11d     192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,409 [INFO]   kube-system   kube-scheduler-master-m001                              1/1     Running     12 (120m ago)   11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,410 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: Pod distribution by node:[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,538 [INFO]   Node master-m003: 39 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,538 [INFO]   Node worker-w005: 13 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,538 [INFO]   Node 15h: 1 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,538 [INFO]   Node worker-w006: 3 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,539 [INFO]   Node worker-w002: 2 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,539 [INFO]   Node worker-w001: 3 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,539 [INFO]   Node master-m002: 2 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,539 [INFO]   Node master-m001: 3 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,539 [INFO]   Node worker-w003: 2 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,539 [INFO]   Node worker-w004: 2 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,539 [INFO]   Node 11d: 3 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,539 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: Filtering for simulation services:[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,659 [INFO] Node master-m001 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,659 [INFO] Node master-m002 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,659 [INFO] Node master-m003 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,660 [INFO] Node worker-w001 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,660 [INFO] Node worker-w002 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,660 [INFO] Node worker-w003 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,660 [INFO] Node worker-w004 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,660 [INFO] Node worker-w005 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,660 [INFO] Node worker-w006 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,663 [WARNING] No pods found for etcd-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,665 [WARNING] No pods found for postgres-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,667 [WARNING] No pods found for redis-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,669 [WARNING] No pods found for nginx-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,670 [WARNING] No pods found for auth-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,671 [INFO] Completed full health check[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,671 [INFO] Simulating node recovery for master-m002 using Kubernetes API[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,688 [INFO] Removed simulated-failure taint from node master-m002[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,698 [INFO] Node master-m002 uncordoned and ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:33,698 [INFO] Node master-m002 powered on (delay 5s)[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:38,701 [INFO] Simulating node recovery for worker-w003 using Kubernetes API[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:38,744 [INFO] Removed simulated-failure taint from node worker-w003[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:38,802 [INFO] Node worker-w003 uncordoned and ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:38,802 [INFO] Node worker-w003 powered on (delay 5s)[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:43,807 [INFO] Simulating node recovery for worker-w004 using Kubernetes API[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:43,823 [INFO] Removed simulated-failure taint from node worker-w004[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:43,834 [INFO] Node worker-w004 uncordoned and ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:43,834 [INFO] Node worker-w004 powered on (delay 5s)[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:56:48,840 [INFO] Waiting 60 seconds for the cluster to stabilize after recovery...[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,873 [INFO] Running final health check[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,873 [INFO] Starting full health check[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,874 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: ============ DETAILED NODE STATUS ============[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,874 [INFO] Basic Node Information (kubectl get nodes -o wide):[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,947 [INFO]   NAME          STATUS   ROLES           AGE   VERSION    INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,947 [INFO]   master-m001   Ready    control-plane   11d   v1.32.11   192.168.56.101   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,947 [INFO]   master-m002   Ready    control-plane   11d   v1.32.11   192.168.56.102   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,947 [INFO]   master-m003   Ready    control-plane   11d   v1.32.11   192.168.56.103   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,947 [INFO]   worker-w001   Ready    <none>          11d   v1.32.11   192.168.56.104   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,947 [INFO]   worker-w002   Ready    <none>          11d   v1.32.11   192.168.56.105   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,948 [INFO]   worker-w003   Ready    <none>          11d   v1.32.11   192.168.56.106   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,948 [INFO]   worker-w004   Ready    <none>          11d   v1.32.11   192.168.56.107   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,948 [INFO]   worker-w005   Ready    <none>          11d   v1.32.11   192.168.56.108   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,948 [INFO]   worker-w006   Ready    <none>          11d   v1.32.11   192.168.56.109   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,948 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: Enhanced Node Status (with taint and cordon indicators):[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:48,948 [INFO]   NAME                STATUS    ROLES           ZONE   CORDONED   TAINTS[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:49,195 [INFO]   master-m001     Ready  ‚úì worker         R1    No       node-role.kubernetes.io/control-plane [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:49,316 [INFO]   master-m002     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:49,459 [INFO]   master-m003     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:49,580 [INFO]   worker-w001     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:49,704 [INFO]   worker-w002     Ready  ‚úì worker         R1    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:49,881 [INFO]   worker-w003     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,088 [INFO]   worker-w004     Ready  ‚úì worker         R2    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,267 [INFO]   worker-w005     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,444 [INFO]   worker-w006     Ready  ‚úì worker         R3    No       None [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,444 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: Legend:[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,444 [INFO]   ‚úì = Node is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,444 [INFO]   ‚ö†Ô∏è = Warning indicator (NotReady, Cordoned, or has simulated-failure taint)[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,444 [INFO] ============ DETAILED POD INFORMATION ============[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,444 [INFO] Running 'kubectl get pods -o wide' to show detailed pod placement:[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,583 [INFO]   NAMESPACE     NAME                                                    READY   STATUS      RESTARTS        AGE     IP                NODE          NOMINATED NODE   READINESS GATES[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,583 [INFO]   argo          argo-server-5c69cb69db-gdkl6                            1/1     Running     0               8d      192.168.221.65    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,583 [INFO]   argo          resilience-bench-ptngm-initialize-metrics-940927476     0/2     Completed   0               3d8h    192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,583 [INFO]   argo          resilience-bench-ptngm-run-health-check-1168793163      0/2     Completed   0               3d8h    192.168.221.67    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-bench-ptngm-run-health-check-1185570782      0/2     Completed   0               3d8h    192.168.221.66    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-bench-ptngm-run-health-check-1202348401      0/2     Completed   0               3d8h    192.168.221.122   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-bench-wf87f-initialize-metrics-3677018408    0/2     Completed   0               3d9h    192.168.221.100   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-bench-wf87f-run-health-check-2914150102      0/2     Completed   0               3d9h    192.168.221.105   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-bench-wf87f-run-health-check-3931060015      0/2     Completed   0               3d9h    192.168.221.104   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-bench-wf87f-run-health-check-3947837634      0/2     Completed   0               3d9h    192.168.221.98    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-bench-wf87f-run-health-check-3964615253      0/2     Completed   0               3d9h    192.168.221.103   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-bench-wf87f-run-node-simulation-4173146970   0/2     Completed   0               3d9h    192.168.221.101   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-bench-wf87f-run-rack-simulation-1356070019   0/2     Completed   0               3d9h    192.168.221.109   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-heft-4cqbx-health-check-1589398418           0/2     Error       0               16h     192.168.15.231    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-heft-4cqbx-heft-initialize-2594215169        0/2     Completed   0               16h     192.168.221.79    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-heft-76kbp-health-check-270747540            0/2     Error       0               16h     192.168.15.237    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-heft-76kbp-heft-initialize-3574960751        0/2     Completed   0               16h     192.168.221.86    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-heft-b85xr-health-check-2840770649           0/2     Error       0               16h     192.168.15.240    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-heft-b85xr-heft-initialize-1754406316        0/2     Completed   0               16h     192.168.221.88    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,584 [INFO]   argo          resilience-heft-fdw9f-health-check-1896357264           0/2     Error       0               16h     192.168.15.235    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,585 [INFO]   argo          resilience-heft-fdw9f-heft-initialize-2651619139        0/2     Completed   0               16h     192.168.221.77    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,585 [INFO]   argo          resilience-heft-gf256-health-check-980174358            0/2     Error       0               16h     192.168.15.236    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,585 [INFO]   argo          resilience-heft-gf256-heft-initialize-1548293021        0/2     Completed   0               16h     192.168.221.84    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,585 [INFO]   argo          resilience-heft-gxwpg-health-check-3445304423           0/2     Error       0               16h     192.168.15.233    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,585 [INFO]   argo          resilience-heft-gxwpg-heft-initialize-2377397022        0/2     Completed   0               16h     192.168.221.81    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,585 [INFO]   argo          resilience-heft-jx8fh-health-check-3032273300           0/2     Completed   0               6m23s   192.168.221.72    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,585 [INFO]   argo          resilience-heft-jx8fh-health-check-3049050919           0/2     Completed   0               6m23s   192.168.221.76    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,585 [INFO]   argo          resilience-heft-jx8fh-health-check-3065828538           0/2     Completed   0               6m23s   192.168.221.74    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,585 [INFO]   argo          resilience-heft-jx8fh-health-check-354772983            0/2     Completed   0               3m12s   192.168.221.78    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,585 [INFO]   argo          resilience-heft-jx8fh-heft-initialize-4056367215        0/2     Completed   0               6m33s   192.168.221.73    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,585 [INFO]   argo          resilience-heft-jx8fh-node-failure-sim-2830132693       0/2     Completed   0               5m51s   192.168.221.75    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,585 [INFO]   argo          resilience-heft-jx8fh-rack-failure-sim-447709032        2/2     Running     0               2m52s   192.168.221.79    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-pc2kb-health-check-3258812212           0/2     Error       0               16h     192.168.15.238    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-pc2kb-heft-initialize-321333135         0/2     Completed   0               16h     192.168.221.83    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-qsmch-health-check-283908068            0/2     Error       0               16h     192.168.15.232    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-qsmch-heft-initialize-1908810015        0/2     Completed   0               16h     192.168.221.82    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-r2w8l-health-check-366927355            0/2     Error       0               16h     192.168.15.239    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-r2w8l-heft-initialize-3054048250        0/2     Completed   0               16h     192.168.221.85    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-t988k-health-check-612195296            0/2     Error       0               16h     192.168.15.234    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-t988k-heft-initialize-164752883         0/2     Completed   0               16h     192.168.221.80    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-vlt2m-health-check-2709447919           0/2     Error       0               15h     192.168.221.119   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-vlt2m-health-check-2726225538           0/2     Error       0               15h     192.168.221.120   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-vlt2m-health-check-2743003157           0/2     Error       0               15h     192.168.221.121   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-vlt2m-heft-initialize-840404112         0/2     Completed   0               15h     192.168.221.118   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-x86wd-health-check-2184182048           0/2     Error       0               15h     192.168.221.123   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-x86wd-health-check-2200959667           0/2     Error       0               15h     192.168.221.125   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-x86wd-health-check-2234514905           0/2     Error       0               15h     192.168.221.124   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,586 [INFO]   argo          resilience-heft-x86wd-heft-initialize-2152040770        0/2     Completed   0               15h     192.168.221.127   master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   argo          workflow-controller-ccbd949dc-t4rx9                     1/1     Running     1 (122m ago)    15h     192.168.195.243   worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   calico-kube-controllers-7498b9bb4c-xd7tb                1/1     Running     0               2d5h    192.168.191.108   worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   calico-node-4zhd4                                       1/1     Running     0               11d     192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   calico-node-75nx6                                       1/1     Running     0               11d     192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   calico-node-7lkdq                                       1/1     Running     0               11d     192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   calico-node-85f8c                                       1/1     Running     0               11d     192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   calico-node-j8nb9                                       1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   calico-node-lbcb2                                       1/1     Running     0               11d     192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   calico-node-wlr5v                                       1/1     Running     0               11d     192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   calico-node-xnzjw                                       1/1     Running     0               11d     192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   calico-node-xsltn                                       1/1     Running     0               11d     192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   coredns-668d6bf9bc-2f74f                                1/1     Running     0               2d7h    192.168.15.230    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   coredns-668d6bf9bc-qnzjq                                1/1     Running     0               15h     192.168.132.176   worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   etcd-master-m001                                        1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   kube-apiserver-master-m001                              1/1     Running     1 (3d2h ago)    11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   kube-controller-manager-master-m001                     1/1     Running     13 (121m ago)   11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,587 [INFO]   kube-system   kube-proxy-5lzhj                                        1/1     Running     0               11d     192.168.56.102    master-m002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,588 [INFO]   kube-system   kube-proxy-7jqkv                                        1/1     Running     0               11d     192.168.56.109    worker-w006   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,588 [INFO]   kube-system   kube-proxy-cv5dt                                        1/1     Running     0               11d     192.168.56.108    worker-w005   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,588 [INFO]   kube-system   kube-proxy-fvpmr                                        1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,588 [INFO]   kube-system   kube-proxy-hgs5z                                        1/1     Running     0               11d     192.168.56.106    worker-w003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,588 [INFO]   kube-system   kube-proxy-kmgqr                                        1/1     Running     0               11d     192.168.56.105    worker-w002   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,588 [INFO]   kube-system   kube-proxy-rdbz5                                        1/1     Running     0               11d     192.168.56.107    worker-w004   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,588 [INFO]   kube-system   kube-proxy-w8mnb                                        1/1     Running     0               11d     192.168.56.103    master-m003   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,588 [INFO]   kube-system   kube-proxy-x9jxr                                        1/1     Running     0               11d     192.168.56.104    worker-w001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,588 [INFO]   kube-system   kube-scheduler-master-m001                              1/1     Running     12 (121m ago)   11d     192.168.56.101    master-m001   <none>           <none>[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,588 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: Pod distribution by node:[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,697 [INFO]   Node master-m003: 39 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,697 [INFO]   Node worker-w005: 13 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,697 [INFO]   Node 15h: 1 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,697 [INFO]   Node worker-w006: 3 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,697 [INFO]   Node worker-w002: 2 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,697 [INFO]   Node worker-w001: 3 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,698 [INFO]   Node master-m002: 2 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,698 [INFO]   Node master-m001: 3 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,698 [INFO]   Node worker-w003: 2 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,698 [INFO]   Node worker-w004: 2 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,698 [INFO]   Node 11d: 3 pods[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,698 [INFO] [0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: Filtering for simulation services:[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,814 [INFO] Node master-m001 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,814 [INFO] Node master-m002 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,814 [INFO] Node master-m003 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,814 [INFO] Node worker-w001 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,814 [INFO] Node worker-w002 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,814 [INFO] Node worker-w003 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,814 [INFO] Node worker-w004 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,814 [INFO] Node worker-w005 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,815 [INFO] Node worker-w006 is Ready[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,817 [WARNING] No pods found for etcd-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,819 [WARNING] No pods found for postgres-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,821 [WARNING] No pods found for redis-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,823 [WARNING] No pods found for nginx-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,825 [WARNING] No pods found for auth-sim[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,825 [INFO] Completed full health check[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: 2026-01-06 05:57:50,825 [INFO] Rack R2 has been fully restored[0m
[36mresilience-heft-jx8fh-rack-failure-sim-447709032: time="2026-01-06T05:57:51.081Z" level=info msg="sub-process exited" argo=true error="<nil>"[0m
[34mresilience-heft-jx8fh-health-check-2943582543: Log directory created/verified: /app/logs[0m
[34mresilience-heft-jx8fh-health-check-2943582543: File logging configured successfully[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,333 [INFO] Loaded in-cluster Kubernetes config[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,333 [INFO] Running on host: resilience-heft-jx8fh-health-check-2943582543[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,333 [INFO] Detected current node: master-m003, zone: R3[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,333 [INFO] Checking if we have permissions to modify nodes...[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,365 [INFO] Testing permissions using node: master-m001[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,372 [INFO] Permission check successful - we can modify nodes[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,373 [INFO] Using real Kubernetes API for node control[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,374 [INFO] Action received: health-check[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,374 [INFO] Stabilization time: 10 seconds[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,374 [INFO] Starting full health check[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,374 [INFO] [0m
[34mresilience-heft-jx8fh-health-check-2943582543: ============ DETAILED NODE STATUS ============[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,374 [INFO] Basic Node Information (kubectl get nodes -o wide):[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,445 [INFO]   NAME          STATUS   ROLES           AGE   VERSION    INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,445 [INFO]   master-m001   Ready    control-plane   11d   v1.32.11   192.168.56.101   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,445 [INFO]   master-m002   Ready    control-plane   11d   v1.32.11   192.168.56.102   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,445 [INFO]   master-m003   Ready    control-plane   11d   v1.32.11   192.168.56.103   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,445 [INFO]   worker-w001   Ready    <none>          11d   v1.32.11   192.168.56.104   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,446 [INFO]   worker-w002   Ready    <none>          11d   v1.32.11   192.168.56.105   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,446 [INFO]   worker-w003   Ready    <none>          11d   v1.32.11   192.168.56.106   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,446 [INFO]   worker-w004   Ready    <none>          11d   v1.32.11   192.168.56.107   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,446 [INFO]   worker-w005   Ready    <none>          11d   v1.32.11   192.168.56.108   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,446 [INFO]   worker-w006   Ready    <none>          11d   v1.32.11   192.168.56.109   <none>        Ubuntu 20.04.6 LTS   5.4.0-216-generic   containerd://1.7.24[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,446 [INFO] [0m
[34mresilience-heft-jx8fh-health-check-2943582543: Enhanced Node Status (with taint and cordon indicators):[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,446 [INFO]   NAME                STATUS    ROLES           ZONE   CORDONED   TAINTS[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,633 [INFO]   master-m001     Ready  ‚úì worker         R1    No       node-role.kubernetes.io/control-plane [0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,796 [INFO]   master-m002     Ready  ‚úì worker         R2    No       None [0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:09,969 [INFO]   master-m003     Ready  ‚úì worker         R3    No       None [0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:10,146 [INFO]   worker-w001     Ready  ‚úì worker         R1    No       None [0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:10,329 [INFO]   worker-w002     Ready  ‚úì worker         R1    No       None [0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:10,512 [INFO]   worker-w003     Ready  ‚úì worker         R2    No       None [0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:10,691 [INFO]   worker-w004     Ready  ‚úì worker         R2    No       None [0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:10,863 [INFO]   worker-w005     Ready  ‚úì worker         R3    No       None [0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,046 [INFO]   worker-w006     Ready  ‚úì worker         R3    No       None [0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,046 [INFO] [0m
[34mresilience-heft-jx8fh-health-check-2943582543: Legend:[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,046 [INFO]   ‚úì = Node is Ready[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,046 [INFO]   ‚ö†Ô∏è = Warning indicator (NotReady, Cordoned, or has simulated-failure taint)[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,046 [INFO] ============ DETAILED POD INFORMATION ============[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,046 [INFO] Running 'kubectl get pods -o wide' to show detailed pod placement:[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,156 [INFO]   NAMESPACE     NAME                                                    READY   STATUS      RESTARTS        AGE     IP                NODE          NOMINATED NODE   READINESS GATES[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,156 [INFO]   argo          argo-server-5c69cb69db-gdkl6                            1/1     Running     0               8d      192.168.221.65    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,156 [INFO]   argo          resilience-bench-ptngm-initialize-metrics-940927476     0/2     Completed   0               3d8h    192.168.221.125   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,156 [INFO]   argo          resilience-bench-ptngm-run-health-check-1168793163      0/2     Completed   0               3d8h    192.168.221.67    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,156 [INFO]   argo          resilience-bench-ptngm-run-health-check-1185570782      0/2     Completed   0               3d8h    192.168.221.66    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,157 [INFO]   argo          resilience-bench-ptngm-run-health-check-1202348401      0/2     Completed   0               3d8h    192.168.221.122   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,157 [INFO]   argo          resilience-bench-wf87f-initialize-metrics-3677018408    0/2     Completed   0               3d9h    192.168.221.100   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,157 [INFO]   argo          resilience-bench-wf87f-run-health-check-2914150102      0/2     Completed   0               3d9h    192.168.221.105   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,157 [INFO]   argo          resilience-bench-wf87f-run-health-check-3931060015      0/2     Completed   0               3d9h    192.168.221.104   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,157 [INFO]   argo          resilience-bench-wf87f-run-health-check-3947837634      0/2     Completed   0               3d9h    192.168.221.98    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,157 [INFO]   argo          resilience-bench-wf87f-run-health-check-3964615253      0/2     Completed   0               3d9h    192.168.221.103   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,157 [INFO]   argo          resilience-bench-wf87f-run-node-simulation-4173146970   0/2     Completed   0               3d9h    192.168.221.101   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,157 [INFO]   argo          resilience-bench-wf87f-run-rack-simulation-1356070019   0/2     Completed   0               3d9h    192.168.221.109   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,157 [INFO]   argo          resilience-heft-4cqbx-health-check-1589398418           0/2     Error       0               16h     192.168.15.231    worker-w005   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,157 [INFO]   argo          resilience-heft-4cqbx-heft-initialize-2594215169        0/2     Completed   0               16h     192.168.221.79    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,157 [INFO]   argo          resilience-heft-76kbp-health-check-270747540            0/2     Error       0               16h     192.168.15.237    worker-w005   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,157 [INFO]   argo          resilience-heft-76kbp-heft-initialize-3574960751        0/2     Completed   0               16h     192.168.221.86    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,157 [INFO]   argo          resilience-heft-b85xr-health-check-2840770649           0/2     Error       0               16h     192.168.15.240    worker-w005   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,158 [INFO]   argo          resilience-heft-b85xr-heft-initialize-1754406316        0/2     Completed   0               16h     192.168.221.88    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,158 [INFO]   argo          resilience-heft-fdw9f-health-check-1896357264           0/2     Error       0               16h     192.168.15.235    worker-w005   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,158 [INFO]   argo          resilience-heft-fdw9f-heft-initialize-2651619139        0/2     Completed   0               16h     192.168.221.77    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,158 [INFO]   argo          resilience-heft-gf256-health-check-980174358            0/2     Error       0               16h     192.168.15.236    worker-w005   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,158 [INFO]   argo          resilience-heft-gf256-heft-initialize-1548293021        0/2     Completed   0               16h     192.168.221.84    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,158 [INFO]   argo          resilience-heft-gxwpg-health-check-3445304423           0/2     Error       0               16h     192.168.15.233    worker-w005   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,158 [INFO]   argo          resilience-heft-gxwpg-heft-initialize-2377397022        0/2     Completed   0               16h     192.168.221.81    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,158 [INFO]   argo          resilience-heft-jx8fh-health-check-2943582543           2/2     Running     0               10s     192.168.221.82    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,158 [INFO]   argo          resilience-heft-jx8fh-health-check-3032273300           0/2     Completed   0               6m44s   192.168.221.72    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,159 [INFO]   argo          resilience-heft-jx8fh-health-check-3049050919           0/2     Completed   0               6m44s   192.168.221.76    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,159 [INFO]   argo          resilience-heft-jx8fh-health-check-3065828538           0/2     Completed   0               6m44s   192.168.221.74    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,159 [INFO]   argo          resilience-heft-jx8fh-health-check-354772983            0/2     Completed   0               3m33s   192.168.221.78    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,159 [INFO]   argo          resilience-heft-jx8fh-heft-initialize-4056367215        0/2     Completed   0               6m54s   192.168.221.73    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,159 [INFO]   argo          resilience-heft-jx8fh-node-failure-sim-2830132693       0/2     Completed   0               6m12s   192.168.221.75    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,159 [INFO]   argo          resilience-heft-jx8fh-rack-failure-sim-447709032        0/2     Completed   0               3m13s   192.168.221.79    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,159 [INFO]   argo          resilience-heft-pc2kb-health-check-3258812212           0/2     Error       0               16h     192.168.15.238    worker-w005   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,159 [INFO]   argo          resilience-heft-pc2kb-heft-initialize-321333135         0/2     Completed   0               16h     192.168.221.83    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,159 [INFO]   argo          resilience-heft-qsmch-health-check-283908068            0/2     Error       0               16h     192.168.15.232    worker-w005   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,160 [INFO]   argo          resilience-heft-qsmch-heft-initialize-1908810015        0/2     Completed   0               16h     192.168.221.82    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,160 [INFO]   argo          resilience-heft-r2w8l-health-check-366927355            0/2     Error       0               16h     192.168.15.239    worker-w005   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,160 [INFO]   argo          resilience-heft-r2w8l-heft-initialize-3054048250        0/2     Completed   0               16h     192.168.221.85    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,160 [INFO]   argo          resilience-heft-t988k-health-check-612195296            0/2     Error       0               16h     192.168.15.234    worker-w005   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,160 [INFO]   argo          resilience-heft-t988k-heft-initialize-164752883         0/2     Completed   0               16h     192.168.221.80    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,160 [INFO]   argo          resilience-heft-vlt2m-health-check-2709447919           0/2     Error       0               15h     192.168.221.119   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,160 [INFO]   argo          resilience-heft-vlt2m-health-check-2726225538           0/2     Error       0               15h     192.168.221.120   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,160 [INFO]   argo          resilience-heft-vlt2m-health-check-2743003157           0/2     Error       0               15h     192.168.221.121   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,161 [INFO]   argo          resilience-heft-vlt2m-heft-initialize-840404112         0/2     Completed   0               15h     192.168.221.118   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,161 [INFO]   argo          resilience-heft-x86wd-health-check-2184182048           0/2     Error       0               15h     192.168.221.123   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,161 [INFO]   argo          resilience-heft-x86wd-health-check-2200959667           0/2     Error       0               15h     192.168.221.125   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,161 [INFO]   argo          resilience-heft-x86wd-health-check-2234514905           0/2     Error       0               15h     192.168.221.124   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,161 [INFO]   argo          resilience-heft-x86wd-heft-initialize-2152040770        0/2     Completed   0               15h     192.168.221.127   master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,161 [INFO]   argo          workflow-controller-ccbd949dc-t4rx9                     1/1     Running     1 (122m ago)    15h     192.168.195.243   worker-w002   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,161 [INFO]   kube-system   calico-kube-controllers-7498b9bb4c-xd7tb                1/1     Running     0               2d5h    192.168.191.108   worker-w006   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,161 [INFO]   kube-system   calico-node-4zhd4                                       1/1     Running     0               11d     192.168.56.105    worker-w002   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,162 [INFO]   kube-system   calico-node-75nx6                                       1/1     Running     0               11d     192.168.56.109    worker-w006   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,162 [INFO]   kube-system   calico-node-7lkdq                                       1/1     Running     0               11d     192.168.56.104    worker-w001   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,162 [INFO]   kube-system   calico-node-85f8c                                       1/1     Running     0               11d     192.168.56.102    master-m002   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,162 [INFO]   kube-system   calico-node-j8nb9                                       1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,162 [INFO]   kube-system   calico-node-lbcb2                                       1/1     Running     0               11d     192.168.56.106    worker-w003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,162 [INFO]   kube-system   calico-node-wlr5v                                       1/1     Running     0               11d     192.168.56.107    worker-w004   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,162 [INFO]   kube-system   calico-node-xnzjw                                       1/1     Running     0               11d     192.168.56.103    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,163 [INFO]   kube-system   calico-node-xsltn                                       1/1     Running     0               11d     192.168.56.108    worker-w005   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,163 [INFO]   kube-system   coredns-668d6bf9bc-2f74f                                1/1     Running     0               2d7h    192.168.15.230    worker-w005   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,163 [INFO]   kube-system   coredns-668d6bf9bc-qnzjq                                1/1     Running     0               15h     192.168.132.176   worker-w001   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,163 [INFO]   kube-system   etcd-master-m001                                        1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,163 [INFO]   kube-system   kube-apiserver-master-m001                              1/1     Running     1 (3d2h ago)    11d     192.168.56.101    master-m001   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,163 [INFO]   kube-system   kube-controller-manager-master-m001                     1/1     Running     13 (122m ago)   11d     192.168.56.101    master-m001   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,163 [INFO]   kube-system   kube-proxy-5lzhj                                        1/1     Running     0               11d     192.168.56.102    master-m002   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,163 [INFO]   kube-system   kube-proxy-7jqkv                                        1/1     Running     0               11d     192.168.56.109    worker-w006   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,163 [INFO]   kube-system   kube-proxy-cv5dt                                        1/1     Running     0               11d     192.168.56.108    worker-w005   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,164 [INFO]   kube-system   kube-proxy-fvpmr                                        1/1     Running     0               11d     192.168.56.101    master-m001   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,164 [INFO]   kube-system   kube-proxy-hgs5z                                        1/1     Running     0               11d     192.168.56.106    worker-w003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,164 [INFO]   kube-system   kube-proxy-kmgqr                                        1/1     Running     0               11d     192.168.56.105    worker-w002   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,164 [INFO]   kube-system   kube-proxy-rdbz5                                        1/1     Running     0               11d     192.168.56.107    worker-w004   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,164 [INFO]   kube-system   kube-proxy-w8mnb                                        1/1     Running     0               11d     192.168.56.103    master-m003   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,164 [INFO]   kube-system   kube-proxy-x9jxr                                        1/1     Running     0               11d     192.168.56.104    worker-w001   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,164 [INFO]   kube-system   kube-scheduler-master-m001                              1/1     Running     12 (122m ago)   11d     192.168.56.101    master-m001   <none>           <none>[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,164 [INFO] [0m
[34mresilience-heft-jx8fh-health-check-2943582543: Pod distribution by node:[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,280 [INFO]   Node master-m003: 40 pods[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,280 [INFO]   Node worker-w005: 13 pods[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,280 [INFO]   Node 15h: 1 pods[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,280 [INFO]   Node worker-w006: 3 pods[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,281 [INFO]   Node worker-w002: 2 pods[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,281 [INFO]   Node worker-w001: 3 pods[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,281 [INFO]   Node master-m002: 2 pods[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,281 [INFO]   Node master-m001: 3 pods[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,281 [INFO]   Node worker-w003: 2 pods[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,281 [INFO]   Node worker-w004: 2 pods[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,281 [INFO]   Node 11d: 3 pods[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,282 [INFO] [0m
[34mresilience-heft-jx8fh-health-check-2943582543: Filtering for simulation services:[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,401 [INFO] Node master-m001 is Ready[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,401 [INFO] Node master-m002 is Ready[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,401 [INFO] Node master-m003 is Ready[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,402 [INFO] Node worker-w001 is Ready[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,402 [INFO] Node worker-w002 is Ready[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,402 [INFO] Node worker-w003 is Ready[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,402 [INFO] Node worker-w004 is Ready[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,402 [INFO] Node worker-w005 is Ready[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,402 [INFO] Node worker-w006 is Ready[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,405 [WARNING] No pods found for etcd-sim[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,407 [WARNING] No pods found for postgres-sim[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,409 [WARNING] No pods found for redis-sim[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,410 [WARNING] No pods found for nginx-sim[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,412 [WARNING] No pods found for auth-sim[0m
[34mresilience-heft-jx8fh-health-check-2943582543: 2026-01-06 05:58:11,412 [INFO] Completed full health check[0m
[34mresilience-heft-jx8fh-health-check-2943582543: time="2026-01-06T05:58:12.030Z" level=info msg="sub-process exited" argo=true error="<nil>"[0m
[35mresilience-heft-jx8fh-finalize-metrics-1950051273: ============================================[0m
[35mresilience-heft-jx8fh-finalize-metrics-1950051273: HEFT-OPTIMIZED RESILIENCE SIMULATION COMPLETE[0m
[35mresilience-heft-jx8fh-finalize-metrics-1950051273: ============================================[0m
[35mresilience-heft-jx8fh-finalize-metrics-1950051273: Workflow: resilience-heft[0m
[35mresilience-heft-jx8fh-finalize-metrics-1950051273: Scheduler: HEFT[0m
[35mresilience-heft-jx8fh-finalize-metrics-1950051273: Logs: /home/vagrant/heft-argo-logs[0m
[35mresilience-heft-jx8fh-finalize-metrics-1950051273: total 240[0m
[35mresilience-heft-jx8fh-finalize-metrics-1950051273: drwxr-xr-x 2 root root   4096 Jan  5 14:13 .[0m
[35mresilience-heft-jx8fh-finalize-metrics-1950051273: drwxr-xr-x 3 root root   4096 Jan  6 05:58 ..[0m
[35mresilience-heft-jx8fh-finalize-metrics-1950051273: -rw-rw-rw- 1 root root 231627 Jan  6 05:58 rack_resilience_simulation.log[0m
[35mresilience-heft-jx8fh-finalize-metrics-1950051273: HEFT simulation completed successfully[0m
[35mresilience-heft-jx8fh-finalize-metrics-1950051273: time="2026-01-06T05:58:28.410Z" level=info msg="sub-process exited" argo=true error="<nil>"[0m
